"""ä¸“é—¨é’ˆå¯¹ä½è¦†ç›–ç‡æ¨¡å—çš„æµ‹è¯•"""
import pytest
import tempfile
import os
from unittest.mock import Mock, patch, AsyncMock
from app.services.ai_service import AIService
from app.services.cache_service import CacheService
from app.services.document_processor import DocumentProcessor
from app.services.export_service import ExportService
from app.services.proposal_generator import ProposalGenerator
from app.services.template_service import TemplateService
from app.services.vector_service import VectorService
from app.services.websocket_manager import WebSocketManager
from app.utils.diff_utils import DiffUtils
from app.utils.security_utils import XSSProtector, sanitize_for_api
from app.core.metrics import ai_calls_total, ai_calls_duration, ai_tokens_used, get_metrics
from app.core.database import engine, SessionLocal
from app.main import app


class TestProposalGeneratorExtended:
    """æ‰©å±•æ–¹æ¡ˆç”Ÿæˆå™¨æµ‹è¯• - å½“å‰è¦†ç›–ç‡18%"""

    def test_proposal_generator_init(self):
        """æµ‹è¯•æ–¹æ¡ˆç”Ÿæˆå™¨åˆå§‹åŒ–"""
        generator = ProposalGenerator()
        assert hasattr(generator, 'ai_service')
        assert hasattr(generator, 'template_service')

    def test_generate_proposal_outline(self):
        """æµ‹è¯•ç”Ÿæˆæ–¹æ¡ˆå¤§çº²"""
        generator = ProposalGenerator()
        
        with patch.object(generator.ai_service, 'generate_text') as mock_generate:
            mock_generate.return_value = "# æ–¹æ¡ˆå¤§çº²\n1. é¡¹ç›®èƒŒæ™¯\n2. è§£å†³æ–¹æ¡ˆ"
            result = generator.generate_proposal_outline("æµ‹è¯•éœ€æ±‚", "ç§‘æŠ€è¡Œä¸š")
            assert "æ–¹æ¡ˆå¤§çº²" in result

    def test_generate_proposal_content(self):
        """æµ‹è¯•ç”Ÿæˆæ–¹æ¡ˆå†…å®¹"""
        generator = ProposalGenerator()
        
        with patch.object(generator.ai_service, 'generate_text') as mock_generate:
            mock_generate.return_value = "è¿™æ˜¯è¯¦ç»†çš„æ–¹æ¡ˆå†…å®¹"
            result = generator.generate_proposal_content("å¤§çº²", "éœ€æ±‚", "æ¨¡æ¿")
            assert result == "è¿™æ˜¯è¯¦ç»†çš„æ–¹æ¡ˆå†…å®¹"

    def test_enhance_proposal_with_ai(self):
        """æµ‹è¯•ä½¿ç”¨AIå¢å¼ºæ–¹æ¡ˆ"""
        generator = ProposalGenerator()
        
        with patch.object(generator.ai_service, 'generate_text') as mock_generate:
            mock_generate.return_value = "å¢å¼ºåçš„æ–¹æ¡ˆå†…å®¹"
            result = generator.enhance_proposal_with_ai("åŸå§‹æ–¹æ¡ˆ", "å¢å¼ºéœ€æ±‚")
            assert result == "å¢å¼ºåçš„æ–¹æ¡ˆå†…å®¹"

    def test_validate_proposal_structure(self):
        """æµ‹è¯•æ–¹æ¡ˆç»“æ„éªŒè¯"""
        generator = ProposalGenerator()
        
        # æœ‰æ•ˆçš„æ–¹æ¡ˆç»“æ„
        valid_proposal = {
            "title": "æµ‹è¯•æ–¹æ¡ˆ",
            "sections": [
                {"title": "æ¦‚è¿°", "content": "å†…å®¹"},
                {"title": "æ–¹æ¡ˆ", "content": "å†…å®¹"}
            ]
        }
        assert generator.validate_proposal_structure(valid_proposal) == True
        
        # æ— æ•ˆçš„æ–¹æ¡ˆç»“æ„
        invalid_proposal = {"title": "æµ‹è¯•æ–¹æ¡ˆ"}
        assert generator.validate_proposal_structure(invalid_proposal) == False

    def test_extract_proposal_requirements(self):
        """æµ‹è¯•æå–æ–¹æ¡ˆéœ€æ±‚"""
        generator = ProposalGenerator()
        
        text = "å®¢æˆ·éœ€è¦ä¸€ä¸ªé«˜æ€§èƒ½çš„ç³»ç»Ÿï¼Œè¦æ±‚å“åº”æ—¶é—´<1ç§’"
        requirements = generator.extract_proposal_requirements(text)
        assert isinstance(requirements, list)

    def test_estimate_proposal_timeline(self):
        """æµ‹è¯•ä¼°ç®—æ–¹æ¡ˆæ—¶é—´çº¿"""
        generator = ProposalGenerator()
        
        tasks = ["éœ€æ±‚åˆ†æ", "ç³»ç»Ÿè®¾è®¡", "å¼€å‘", "æµ‹è¯•"]
        timeline = generator.estimate_proposal_timeline(tasks)
        assert isinstance(timeline, dict)
        assert "total_days" in timeline

    def test_generate_proposal_risks(self):
        """æµ‹è¯•ç”Ÿæˆæ–¹æ¡ˆé£é™©åˆ†æ"""
        generator = ProposalGenerator()
        
        with patch.object(generator.ai_service, 'generate_text') as mock_generate:
            mock_generate.return_value = "æŠ€æœ¯é£é™©ï¼šæ€§èƒ½é—®é¢˜\nç®¡ç†é£é™©ï¼šè¿›åº¦å»¶æœŸ"
            risks = generator.generate_proposal_risks("æµ‹è¯•æ–¹æ¡ˆ")
            assert "æŠ€æœ¯é£é™©" in risks

    def test_format_proposal_output(self):
        """æµ‹è¯•æ ¼å¼åŒ–æ–¹æ¡ˆè¾“å‡º"""
        generator = ProposalGenerator()
        
        proposal_data = {
            "title": "æµ‹è¯•æ–¹æ¡ˆ",
            "customer": "æµ‹è¯•å®¢æˆ·",
            "content": "æ–¹æ¡ˆå†…å®¹"
        }
        formatted = generator.format_proposal_output(proposal_data, format_type="markdown")
        assert isinstance(formatted, str)


class TestAIServiceDeepCoverage:
    """AIæœåŠ¡æ·±åº¦æµ‹è¯• - æå‡å½“å‰51%è¦†ç›–ç‡"""

    def test_ai_service_error_handling(self):
        """æµ‹è¯•AIæœåŠ¡é”™è¯¯å¤„ç†"""
        service = AIService()
        
        # æµ‹è¯•ç½‘ç»œé”™è¯¯
        with patch('httpx.AsyncClient.post') as mock_post:
            mock_post.side_effect = Exception("ç½‘ç»œé”™è¯¯")
            with pytest.raises(Exception):
                import asyncio
                asyncio.run(service.generate_text("æµ‹è¯•"))

    def test_ai_service_token_validation(self):
        """æµ‹è¯•AIæœåŠ¡ä»¤ç‰ŒéªŒè¯"""
        service = AIService()
        
        # æµ‹è¯•æ— æ•ˆä»¤ç‰Œ
        with patch.object(service, '_validate_api_key') as mock_validate:
            mock_validate.return_value = False
            with pytest.raises(Exception):
                import asyncio
                asyncio.run(service.generate_text("æµ‹è¯•"))

    def test_ai_service_response_parsing(self):
        """æµ‹è¯•AIæœåŠ¡å“åº”è§£æ"""
        service = AIService()
        
        # æµ‹è¯•JSONå“åº”è§£æ
        with patch.object(service, '_parse_json_response') as mock_parse:
            mock_parse.return_value = {"content": "è§£æçš„å†…å®¹"}
            result = mock_parse('{"content": "è§£æçš„å†…å®¹"}')
            assert result["content"] == "è§£æçš„å†…å®¹"

    def test_ai_service_concurrent_limiting(self):
        """æµ‹è¯•AIæœåŠ¡å¹¶å‘é™åˆ¶"""
        service = AIService()
        
        with patch.object(service, '_check_rate_limit') as mock_check:
            mock_check.return_value = True  # è¢«é™åˆ¶
            with pytest.raises(Exception):
                import asyncio
                asyncio.run(service.generate_text("æµ‹è¯•"))

    def test_ai_service_fallback_mechanism(self):
        """æµ‹è¯•AIæœåŠ¡å›é€€æœºåˆ¶"""
        service = AIService()
        original_provider = service.provider
        
        # æµ‹è¯•æä¾›å•†å›é€€
        service.provider = "unavailable"
        with patch.object(service, '_try_providers') as mock_try:
            mock_try.return_value = "å›é€€å†…å®¹"
            import asyncio
            result = asyncio.run(service.generate_text("æµ‹è¯•"))
            assert result == "å›é€€å†…å®¹"
        
        service.provider = original_provider

    def test_ai_service_content_filtering(self):
        """æµ‹è¯•AIæœåŠ¡å†…å®¹è¿‡æ»¤"""
        service = AIService()
        
        # æµ‹è¯•æ•æ„Ÿå†…å®¹è¿‡æ»¤
        sensitive_content = "è¿™æ˜¯æ•æ„Ÿå†…å®¹"
        filtered = service._filter_sensitive_content(sensitive_content)
        assert isinstance(filtered, str)

    def test_ai_service_usage_tracking(self):
        """æµ‹è¯•AIæœåŠ¡ä½¿ç”¨è·Ÿè¸ª"""
        service = AIService()
        
        # æµ‹è¯•ä½¿ç”¨ç»Ÿè®¡
        service._track_usage("openai", 100, 10)
        assert hasattr(service, 'usage_stats')

    def test_ai_service_cache_integration(self):
        """æµ‹è¯•AIæœåŠ¡ç¼“å­˜é›†æˆ"""
        service = AIService()
        
        with patch.object(service.cache_service, 'get') as mock_get, \
             patch.object(service.cache_service, 'set') as mock_set:
            mock_get.return_value = None  # ç¼“å­˜æœªå‘½ä¸­
            with patch.object(service, '_generate_with_openai') as mock_generate:
                mock_generate.return_value = ("ç”Ÿæˆå†…å®¹", 10)
                import asyncio
                result = asyncio.run(service.generate_text("æµ‹è¯•"))
                assert result == "ç”Ÿæˆå†…å®¹"


class TestCacheServiceDeepCoverage:
    """ç¼“å­˜æœåŠ¡æ·±åº¦æµ‹è¯• - æå‡å½“å‰49%è¦†ç›–ç‡"""

    def test_cache_service_distributed_operations(self):
        """æµ‹è¯•åˆ†å¸ƒå¼ç¼“å­˜æ“ä½œ"""
        service = CacheService()
        
        # æµ‹è¯•åˆ†å¸ƒå¼é”
        with patch.object(service, '_acquire_distributed_lock') as mock_lock:
            mock_lock.return_value = True
            lock_acquired = service._acquire_distributed_lock("test_lock")
            assert lock_acquired == True

    def test_cache_service_serialization(self):
        """æµ‹è¯•ç¼“å­˜åºåˆ—åŒ–"""
        service = CacheService()
        
        # æµ‹è¯•å¤æ‚æ•°æ®åºåˆ—åŒ–
        complex_data = {
            "nested": {"dict": {"with": [1, 2, 3]}},
            "list": [{"a": 1}, {"b": 2}],
            "function": lambda x: x + 1
        }
        
        serialized = service._serialize_data(complex_data)
        assert isinstance(serialized, str)

    def test_cache_service_memory_management(self):
        """æµ‹è¯•ç¼“å­˜å†…å­˜ç®¡ç†"""
        service = CacheService()
        
        # æµ‹è¯•å†…å­˜ä½¿ç”¨æ£€æŸ¥
        memory_usage = service._check_memory_usage()
        assert isinstance(memory_usage, dict)
        assert "used_memory" in memory_usage

    def test_cache_service_eviction_policies(self):
        """æµ‹è¯•ç¼“å­˜æ·˜æ±°ç­–ç•¥"""
        service = CacheService()
        
        # æµ‹è¯•LRUæ·˜æ±°
        service.set("key1", "value1", ttl=1)
        service.set("key2", "value2", ttl=1)
        service.set("key3", "value3", ttl=1)
        
        # å¼ºåˆ¶æ·˜æ±°
        service._evict_expired_items()
        
        # æ£€æŸ¥æ˜¯å¦æ·˜æ±°
        assert service.get("key1") is None

    def test_cache_service_health_monitoring(self):
        """æµ‹è¯•ç¼“å­˜å¥åº·ç›‘æ§"""
        service = CacheService()
        
        # æµ‹è¯•å¥åº·æ£€æŸ¥
        health = service.check_health()
        assert "redis_connected" in health
        assert "memory_cache_size" in health

    def test_cache_service_backup_and_restore(self):
        """æµ‹è¯•ç¼“å­˜å¤‡ä»½å’Œæ¢å¤"""
        service = CacheService()
        
        # æ·»åŠ ä¸€äº›æ•°æ®
        service.set("backup_key", "backup_value")
        
        # å¤‡ä»½æ•°æ®
        backup_data = service._create_backup()
        assert isinstance(backup_data, dict)
        
        # æ¸…ç©ºç¼“å­˜
        service.clear_all()
        
        # æ¢å¤æ•°æ®
        service._restore_from_backup(backup_data)
        assert service.get("backup_key") == "backup_value"

    def test_cache_service_performance_metrics(self):
        """æµ‹è¯•ç¼“å­˜æ€§èƒ½æŒ‡æ ‡"""
        service = CacheService()
        
        # æµ‹è¯•æ€§èƒ½ç»Ÿè®¡
        metrics = service.get_performance_metrics()
        assert "hit_rate" in metrics
        assert "avg_response_time" in metrics


class TestDiffUtilsCoverage:
    """å·®å¼‚å·¥å…·æµ‹è¯• - æå‡å½“å‰0%è¦†ç›–ç‡"""

    def test_diff_utils_calculate_text_diff(self):
        """æµ‹è¯•æ–‡æœ¬å·®å¼‚è®¡ç®—"""
        text1 = "åŸå§‹æ–‡æœ¬å†…å®¹"
        text2 = "ä¿®æ”¹åçš„æ–‡æœ¬å†…å®¹"
        
        diff_result = DiffUtils.calculate_text_diff(text1, text2)
        assert isinstance(diff_result, dict)
        assert "total_changes" in diff_result
        assert "similarity" in diff_result
        assert "diff" in diff_result

    def test_diff_utils_calculate_html_diff(self):
        """æµ‹è¯•HTMLå·®å¼‚è®¡ç®—"""
        text1 = "åŸå§‹æ–‡æœ¬å†…å®¹"
        text2 = "ä¿®æ”¹åçš„æ–‡æœ¬å†…å®¹"
        
        html_diff = DiffUtils.calculate_html_diff(text1, text2)
        assert isinstance(html_diff, str)
        assert "<table" in html_diff

    def test_diff_utils_compare_json_content(self):
        """æµ‹è¯•JSONå†…å®¹æ¯”è¾ƒ"""
        json1 = {"name": "test", "value": 1, "items": ["a", "b"]}
        json2 = {"name": "test", "value": 2, "items": ["a", "c"]}
        
        diff_result = DiffUtils.compare_json_content(json1, json2)
        assert isinstance(diff_result, dict)
        assert "fields_changed" in diff_result
        assert "fields_added" in diff_result
        assert "fields_removed" in diff_result
        assert "summary" in diff_result

    def test_diff_utils_comprehensive_workflow(self):
        """æµ‹è¯•å®Œæ•´çš„å·®å¼‚å·¥ä½œæµ"""
        original_text = "è¿™æ˜¯åŸå§‹çš„æ–‡æ¡£å†…å®¹\nåŒ…å«å¤šè¡Œæ–‡æœ¬"
        modified_text = "è¿™æ˜¯ä¿®æ”¹åçš„æ–‡æ¡£å†…å®¹\nåŒ…å«æ›´æ–°åçš„æ–‡æœ¬\næ–°å¢äº†ä¸€è¡Œ"
        
        # è®¡ç®—æ–‡æœ¬å·®å¼‚
        text_diff = DiffUtils.calculate_text_diff(text1=original_text, text2=modified_text)
        assert text_diff["total_changes"] > 0
        
        # è®¡ç®—HTMLå·®å¼‚
        html_diff = DiffUtils.calculate_html_diff(text1=original_text, text2=modified_text)
        assert len(html_diff) > 0
        
        # æ¯”è¾ƒJSONå†…å®¹
        json1 = {"title": "åŸå§‹æ ‡é¢˜", "content": original_text}
        json2 = {"title": "ä¿®æ”¹æ ‡é¢˜", "content": modified_text, "author": "æµ‹è¯•ä½œè€…"}
        
        json_diff = DiffUtils.compare_json_content(json1, json2)
        assert json_diff["summary"]["changed_fields"] >= 1
        assert json_diff["summary"]["added_fields"] >= 1

    def test_diff_utils_edge_cases(self):
        """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
        # ç©ºæ–‡æœ¬
        empty_diff = DiffUtils.calculate_text_diff("", "")
        assert empty_diff["total_changes"] == 0
        assert empty_diff["similarity"] == 1.0
        
        # ä¸€æ–¹ä¸ºç©º
        single_empty = DiffUtils.calculate_text_diff("æœ‰å†…å®¹", "")
        assert single_empty["total_changes"] > 0
        
        # ç›¸åŒæ–‡æœ¬
        same_diff = DiffUtils.calculate_text_diff("ç›¸åŒå†…å®¹", "ç›¸åŒå†…å®¹")
        assert same_diff["total_changes"] == 0
        assert same_diff["similarity"] == 1.0
        
        # ç©ºJSON
        empty_json_diff = DiffUtils.compare_json_content({}, {})
        assert empty_json_diff["summary"]["total_fields"] == 0

    def test_diff_utils_large_content(self):
        """æµ‹è¯•å¤§å†…å®¹å¤„ç†"""
        # åˆ›å»ºå¤§æ–‡æœ¬
        large_text1 = "è¡Œ" + "\nè¡Œ" * 1000 + "ç»“æŸ"
        large_text2 = "è¡Œ" + "\nè¡Œ" * 1000 + "ä¿®æ”¹" + "\nè¡Œ" + "ç»“æŸ"
        
        # åº”è¯¥èƒ½å¤„ç†å¤§æ–‡æœ¬è€Œä¸å‡ºé”™
        diff_result = DiffUtils.calculate_text_diff(large_text1, large_text2)
        assert isinstance(diff_result, dict)
        assert diff_result["total_changes"] > 0
        
        # æµ‹è¯•å¤§JSON
        large_json1 = {"data": [{"id": i} for i in range(100)]}
        large_json2 = {"data": [{"id": i} for i in range(101)]}
        
        json_diff = DiffUtils.compare_json_content(large_json1, large_json2)
        assert isinstance(json_diff, dict)

    def test_diff_utils_unicode_handling(self):
        """æµ‹è¯•Unicodeå¤„ç†"""
        unicode_text1 = "ä¸­æ–‡å†…å®¹ ğŸš€\nØ§Ù„Ø¹Ø±Ø¨ÙŠØ©\nÑ€ÑƒÑÑĞºĞ¸Ğ¹"
        unicode_text2 = "ä¸­æ–‡å†…å®¹æ›´æ–° ğŸ‰\nØ§Ù„Ø¹Ø±Ø¨ÙŠØ©\næ—¥æœ¬èª"
        
        diff_result = DiffUtils.calculate_text_diff(unicode_text1, unicode_text2)
        assert isinstance(diff_result, dict)
        assert diff_result["total_changes"] > 0
        
        html_diff = DiffUtils.calculate_html_diff(unicode_text1, unicode_text2)
        assert isinstance(html_diff, str)
        
        # æµ‹è¯•Unicode JSON
        unicode_json1 = {"ä¸­æ–‡": "å†…å®¹", "emoji": "ğŸš€", "arabic": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"}
        unicode_json2 = {"ä¸­æ–‡": "å†…å®¹æ›´æ–°", "emoji": "ğŸ‰", "japanese": "æ—¥æœ¬èª"}
        
        json_diff = DiffUtils.compare_json_content(unicode_json1, unicode_json2)
        assert isinstance(json_diff, dict)


class TestSecurityUtilsCoverage:
    """å®‰å…¨å·¥å…·æµ‹è¯• - æå‡å½“å‰26%è¦†ç›–ç‡"""

    def test_xss_protector_sanitize_html_comprehensive(self):
        """æµ‹è¯•å…¨é¢çš„HTMLæ¸…ç†"""
        test_cases = [
            ("<script>alert('xss')</script>", "alert('xss')"),
            ("<img src='x' onerror='alert(1)'>", ""),
            ("<a href='javascript:alert(1)'>link</a>", "link"),
            ("<div onclick='alert(1)'>content</div>", "content"),
            ("<iframe src='javascript:alert(1)'></iframe>", ""),
            ("<object data='javascript:alert(1)'></object>", ""),
            ("<embed src='javascript:alert(1)'>", ""),
            ("<link rel='stylesheet' href='javascript:alert(1)'>", "")
        ]
        
        for malicious, expected in test_cases:
            result = XSSProtector.sanitize_html(malicious)
            assert "<script" not in result
            assert "javascript:" not in result.lower()

    def test_xss_protector_is_dangerous_content_comprehensive(self):
        """æµ‹è¯•å±é™©å†…å®¹æ£€æµ‹"""
        dangerous_patterns = [
            "javascript:alert('xss')",
            "<script>alert('xss')</script>",
            "onload='alert(1)'",
            "onerror='alert(1)'",
            "<iframe src='evil.com'></iframe>",
            "<object data='evil.swf'></object>",
            "<embed src='evil.mp4'>",
            "<link href='evil.css'>"
        ]
        
        for pattern in dangerous_patterns:
            assert XSSProtector.is_dangerous_content(pattern) == True
        
        # æµ‹è¯•å®‰å…¨å†…å®¹
        safe_content = "è¿™æ˜¯å®‰å…¨çš„å†…å®¹ï¼Œæ²¡æœ‰å±é™©æ ‡ç­¾"
        assert XSSProtector.is_dangerous_content(safe_content) == False

    def test_xss_protector_validate_url_comprehensive(self):
        """æµ‹è¯•URLéªŒè¯"""
        safe_urls = [
            "https://example.com",
            "http://example.com/path",
            "ftp://files.example.com",
            "mailto:user@example.com"
        ]
        
        for url in safe_urls:
            assert XSSProtector.validate_url(url) == True
        
        dangerous_urls = [
            "javascript:alert('xss')",
            "vbscript:msgbox('xss')",
            "data:text/html,<script>alert('xss')</script>",
            "file:///etc/passwd"
        ]
        
        for url in dangerous_urls:
            assert XSSProtector.validate_url(url) == False

    def test_xss_protector_sanitize_css(self):
        """æµ‹è¯•CSSæ¸…ç†"""
        malicious_css = "background-image: url('javascript:alert(1)')"
        safe_css = XSSProtector.sanitize_css(malicious_css)
        assert "javascript:" not in safe_css

    def test_sanitize_for_api_edge_cases(self):
        """æµ‹è¯•APIæ•°æ®æ¸…ç†è¾¹ç•Œæƒ…å†µ"""
        # Noneå€¼
        assert sanitize_for_api(None) is None
        
        # ç©ºå€¼
        assert sanitize_for_api("") == ""
        
        # æ•°å­—
        assert sanitize_for_api(123) == 123
        
        # å¸ƒå°”å€¼
        assert sanitize_for_api(True) == True
        
        # åµŒå¥—ç»“æ„
        nested = {
            "safe": "å®‰å…¨å†…å®¹",
            "dangerous": "<script>alert('xss')</script>",
            "nested": {
                "array": ["å®‰å…¨", "<script>alert(1)</script>", 123]
            }
        }
        result = sanitize_for_api(nested)
        assert "<script>" not in result["dangerous"]
        assert "<script>" not in result["nested"]["array"][1]

    def test_sanitize_for_api_large_data(self):
        """æµ‹è¯•å¤§æ•°æ®é‡æ¸…ç†"""
        large_list = ["item" + str(i) for i in range(1000)]
        result = sanitize_for_api(large_list)
        assert len(result) == 1000

    def test_sanitize_for_api_unicode(self):
        """æµ‹è¯•Unicodeå­—ç¬¦æ¸…ç†"""
        unicode_data = {
            "chinese": "ä¸­æ–‡å†…å®¹",
            "emoji": "ğŸš€ğŸ‰",
            "arabic": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
            "special": "ç‰¹æ®Šå­—ç¬¦ÃŸÃ¸Ã±"
        }
        result = sanitize_for_api(unicode_data)
        assert result["chinese"] == "ä¸­æ–‡å†…å®¹"
        assert result["emoji"] == "ğŸš€ğŸ‰"


class TestMetricsCoverage:
    """æŒ‡æ ‡æ”¶é›†æµ‹è¯• - æå‡å½“å‰26%è¦†ç›–ç‡"""

    def test_metrics_basic_functions(self):
        """æµ‹è¯•æŒ‡æ ‡åŸºæœ¬åŠŸèƒ½"""
        # æµ‹è¯•AIè°ƒç”¨æŒ‡æ ‡
        ai_calls_total.labels(provider="openai", model="gpt-3.5", status="success").inc()
        ai_calls_duration.labels(provider="openai", model="gpt-3.5").observe(0.5)
        ai_tokens_used.labels(provider="openai", model="gpt-3.5").inc(100)
        
        # æµ‹è¯•å‘é‡æœç´¢æŒ‡æ ‡
        vector_search_total.labels(collection="documents", status="success").inc()
        
        # è·å–æŒ‡æ ‡
        metrics_data = get_metrics()
        assert isinstance(metrics_data, str)
        assert len(metrics_data) > 0

    def test_cache_hit_rate_function(self):
        """æµ‹è¯•ç¼“å­˜å‘½ä¸­ç‡å‡½æ•°"""
        from app.core.metrics import update_cache_hit_rate
        
        # æ›´æ–°ç¼“å­˜å‘½ä¸­ç‡
        update_cache_hit_rate("redis", 80, 100)
        update_cache_hit_rate("memory", 60, 100)
        
        # éªŒè¯å‡½æ•°ä¸ä¼šæŠ›å‡ºå¼‚å¸¸
        assert True

    def test_metric_decorators(self):
        """æµ‹è¯•æŒ‡æ ‡è£…é¥°å™¨"""
        from app.core.metrics import track_ai_metrics, track_vector_search_metrics, track_cache_metrics
        
        # æµ‹è¯•è£…é¥°å™¨åˆ›å»º
        ai_decorator = track_ai_metrics("openai", "gpt-3.5")
        vector_decorator = track_vector_search_metrics("documents")
        cache_decorator = track_cache_metrics("redis", "get")
        
        # éªŒè¯è£…é¥°å™¨å­˜åœ¨
        assert callable(ai_decorator)
        assert callable(vector_decorator)
        assert callable(cache_decorator)

    def test_metrics_counter_operations(self):
        """æµ‹è¯•æŒ‡æ ‡è®¡æ•°å™¨æ“ä½œ"""
        # æµ‹è¯•ä¸åŒçŠ¶æ€
        ai_calls_total.labels(provider="zhipu", model="chatglm", status="success").inc()
        ai_calls_total.labels(provider="zhipu", model="chatglm", status="error").inc()
        ai_calls_total.labels(provider="wenxin", model="ernie", status="success").inc()
        
        # æµ‹è¯•tokenè®¡æ•°
        ai_tokens_used.labels(provider="zhipu", model="chatglm").inc(50)
        ai_tokens_used.labels(provider="wenxin", model="ernie").inc(75)
        
        # éªŒè¯ä¸ä¼šæŠ›å‡ºå¼‚å¸¸
        assert True

    def test_metrics_histogram_operations(self):
        """æµ‹è¯•æŒ‡æ ‡ç›´æ–¹å›¾æ“ä½œ"""
        # æµ‹è¯•AIè°ƒç”¨æŒç»­æ—¶é—´
        for duration in [0.1, 0.2, 0.3, 0.5, 1.0]:
            ai_calls_duration.labels(provider="openai", model="gpt-3.5").observe(duration)
        
        # æµ‹è¯•å¤šä¸ªæ¨¡å‹
        ai_calls_duration.labels(provider="zhipu", model="chatglm").observe(0.4)
        ai_calls_duration.labels(provider="wenxin", model="ernie").observe(0.6)
        
        # éªŒè¯ä¸ä¼šæŠ›å‡ºå¼‚å¸¸
        assert True

    def test_metrics_gauge_operations(self):
        """æµ‹è¯•æŒ‡æ ‡ä»ªè¡¨æ“ä½œ"""
        from app.core.metrics import cache_size, active_connections
        
        # æµ‹è¯•ç¼“å­˜å¤§å°
        cache_size.labels(cache_type="redis").set(1000)
        cache_size.labels(cache_type="memory").set(500)
        
        # æµ‹è¯•æ´»è·ƒè¿æ¥
        active_connections.labels(service="websocket").set(10)
        active_connections.labels(service="api").set(50)
        
        # éªŒè¯ä¸ä¼šæŠ›å‡ºå¼‚å¸¸
        assert True


class TestWebSocketManagerCoverage:
    """WebSocketç®¡ç†å™¨æµ‹è¯• - æå‡å½“å‰31%è¦†ç›–ç‡"""

    def test_websocket_manager_message_broadcasting(self):
        """æµ‹è¯•æ¶ˆæ¯å¹¿æ’­"""
        manager = WebSocketManager()
        
        # åˆ›å»ºæ¨¡æ‹Ÿè¿æ¥
        websocket1 = Mock()
        websocket2 = Mock()
        
        # æ·»åŠ è¿æ¥
        manager.add_connection(websocket1, 1)
        manager.add_connection(websocket2, 2)
        
        # å¹¿æ’­æ¶ˆæ¯
        message = {"type": "broadcast", "content": "æµ‹è¯•æ¶ˆæ¯"}
        manager.broadcast(message)
        
        # éªŒè¯æ‰€æœ‰è¿æ¥éƒ½æ”¶åˆ°äº†æ¶ˆæ¯
        websocket1.send_json.assert_called_once_with(message)
        websocket2.send_json.assert_called_once_with(message)

    def test_websocket_manager_user_messaging(self):
        """æµ‹è¯•ç”¨æˆ·æ¶ˆæ¯å‘é€"""
        manager = WebSocketManager()
        
        # åˆ›å»ºæ¨¡æ‹Ÿè¿æ¥
        websocket1 = Mock()
        websocket2 = Mock()
        
        # æ·»åŠ è¿æ¥ï¼ˆåŒä¸€ç”¨æˆ·å¤šä¸ªè¿æ¥ï¼‰
        manager.add_connection(websocket1, 1)
        manager.add_connection(websocket2, 1)
        
        # å‘é€ç»™ç‰¹å®šç”¨æˆ·
        message = {"type": "user_message", "content": "ä¸ªäººæ¶ˆæ¯"}
        manager.send_to_user(1, message)
        
        # éªŒè¯è¯¥ç”¨æˆ·çš„æ‰€æœ‰è¿æ¥éƒ½æ”¶åˆ°äº†æ¶ˆæ¯
        websocket1.send_json.assert_called_once_with(message)
        websocket2.send_json.assert_called_once_with(message)

    def test_websocket_manager_connection_stats(self):
        """æµ‹è¯•è¿æ¥ç»Ÿè®¡"""
        manager = WebSocketManager()
        
        # æ·»åŠ ä¸€äº›è¿æ¥
        for i in range(5):
            websocket = Mock()
            user_id = i // 2  # æ¨¡æ‹Ÿå¤šä¸ªç”¨æˆ·
            manager.add_connection(websocket, user_id)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = manager.get_connection_stats()
        assert "total_connections" in stats
        assert "unique_users" in stats
        assert stats["total_connections"] == 5
        assert stats["unique_users"] == 3

    def test_websocket_manager_connection_cleanup(self):
        """æµ‹è¯•è¿æ¥æ¸…ç†"""
        manager = WebSocketManager()
        
        # æ·»åŠ è¿æ¥
        websocket = Mock()
        manager.add_connection(websocket, 1)
        
        # ç§»é™¤è¿æ¥
        manager.remove_connection(websocket)
        
        # éªŒè¯è¿æ¥å·²ç§»é™¤
        assert len(manager.connections) == 0
        assert 1 not in manager.user_connections

    def test_websocket_manager_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        manager = WebSocketManager()
        
        # åˆ›å»ºä¼šæŠ›å‡ºå¼‚å¸¸çš„WebSocket
        faulty_websocket = Mock()
        faulty_websocket.send_json.side_effect = Exception("è¿æ¥é”™è¯¯")
        
        # æ·»åŠ è¿æ¥
        manager.add_connection(faulty_websocket, 1)
        
        # å‘é€æ¶ˆæ¯ï¼ˆåº”è¯¥å¤„ç†é”™è¯¯ï¼‰
        message = {"type": "test", "content": "æµ‹è¯•"}
        manager.send_to_user(1, message)
        
        # éªŒè¯æ²¡æœ‰æŠ›å‡ºå¼‚å¸¸
        assert True  # å¦‚æœèƒ½æ‰§è¡Œåˆ°è¿™é‡Œè¯´æ˜é”™è¯¯è¢«æ­£ç¡®å¤„ç†

    def test_websocket_manager_room_functionality(self):
        """æµ‹è¯•æˆ¿é—´åŠŸèƒ½"""
        manager = WebSocketManager()
        
        # åˆ›å»ºæ¨¡æ‹Ÿè¿æ¥
        websocket1 = Mock()
        websocket2 = Mock()
        websocket3 = Mock()
        
        # æ·»åŠ è¿æ¥å¹¶åŠ å…¥æˆ¿é—´
        manager.add_connection(websocket1, 1)
        manager.add_connection(websocket2, 2)
        manager.add_connection(websocket3, 3)
        
        manager.join_room(websocket1, "room1")
        manager.join_room(websocket2, "room1")
        manager.join_room(websocket3, "room2")
        
        # å‘æˆ¿é—´å‘é€æ¶ˆæ¯
        room_message = {"type": "room_message", "content": "æˆ¿é—´æ¶ˆæ¯"}
        manager.send_to_room("room1", room_message)
        
        # éªŒè¯æˆ¿é—´å†…çš„ç”¨æˆ·æ”¶åˆ°æ¶ˆæ¯
        websocket1.send_json.assert_called_once_with(room_message)
        websocket2.send_json.assert_called_once_with(room_message)
        websocket3.send_json.assert_not_called()  # ä¸åœ¨æˆ¿é—´å†…

    def test_websocket_manager_connection_timeout(self):
        """æµ‹è¯•è¿æ¥è¶…æ—¶"""
        manager = WebSocketManager()
        
        # æ¨¡æ‹Ÿè¶…æ—¶æ£€æŸ¥
        import time
        current_time = time.time()
        
        # æ·»åŠ è¿æ¥å¹¶è®¾ç½®æœ€åæ´»åŠ¨æ—¶é—´
        websocket = Mock()
        manager.add_connection(websocket, 1)
        manager.user_last_activity[1] = current_time - 3600  # 1å°æ—¶å‰
        
        # æ¸…ç†è¶…æ—¶è¿æ¥
        timeout_removed = manager.cleanup_timeout_connections(timeout=1800)  # 30åˆ†é’Ÿè¶…æ—¶
        assert timeout_removed >= 1