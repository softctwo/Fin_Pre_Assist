# 金融售前方案辅助编写系统 - 安装部署手册

## 文档信息

| 项目 | 内容 |
|------|------|
| 文档名称 | 安装部署手册 |
| 产品名称 | 金融售前方案辅助编写系统 |
| 版本 | v1.2.0 |
| 发布日期 | 2025-01-08 |
| 作者 | 运维团队 |
| 状态 | 正式发布 |
| 目标读者 | 系统管理员、运维工程师、DevOps工程师 |

## 版本历史

| 版本 | 日期 | 修改人 | 修改内容 |
|------|------|--------|----------|
| v1.0.0 | 2024-12-01 | 运维团队 | 初始版本创建 |
| v1.1.0 | 2024-12-15 | 运维团队 | 增加容器化部署方案 |
| v1.2.0 | 2025-01-08 | 运维团队 | 完善高可用部署配置 |

## 1. 部署概述

### 1.1 部署架构

金融售前方案辅助编写系统采用**云原生微服务架构**，支持多种部署方式：

- **容器化部署**（推荐）：Docker + Kubernetes
- **传统部署**：直接安装在虚拟机或物理服务器
- **混合云部署**：部分服务在云端，部分在本地
- **边缘部署**：轻量级部署在边缘节点

### 1.2 系统架构图

```
┌─────────────────────────────────────────────────────────────┐
│                      负载均衡层                              │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐         │
│  │   Nginx     │ │   HAProxy   │ │  Cloud LB   │         │
│  │  (Ingress)  │ │  (L4负载)   │ │  (云负载)   │         │
│  └─────────────┘ └─────────────┘ └─────────────┘         │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                    API网关层                                 │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐         │
│  │   Kong      │ │   Nginx     │ │   WAF       │         │
│  │  (API网关)  │ │  (反向代理) │ │ (防火墙)    │         │
│  └─────────────┘ └─────────────┘ └─────────────┘         │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                   应用服务层                                │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐         │
│  │  用户服务   │ │  文档服务   │ │  AI服务     │         │
│  │  (Pod组)    │ │  (Pod组)    │ │  (Pod组)    │         │
│  └─────────────┘ └─────────────┘ └─────────────┘         │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐         │
│  │ 知识库服务  │ │ 模板服务    │ │ 导出服务    │         │
│  │  (Pod组)    │ │  (Pod组)    │ │  (Pod组)    │         │
│  └─────────────┘ └─────────────┘ └─────────────┘         │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                    数据存储层                                │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐         │
│  │ PostgreSQL  │ │    Redis    │ │ Elasticsearch│         │
│  │   (主库)    │ │  (缓存)     │ │  (搜索)     │         │
│  └─────────────┘ └─────────────┘ └─────────────┘         │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐         │
│  │  Qdrant     │ │   MinIO     │ │  备份存储   │         │
│  │ (向量库)    │ │ (对象存储)  │ │ (异地备份)  │         │
│  └─────────────┘ └─────────────┘ └─────────────┘         │
└─────────────────────────────────────────────────────────────┘
```

### 1.3 部署方式对比

| 部署方式 | 适用场景 | 优点 | 缺点 | 推荐度 |
|----------|----------|------|------|--------|
| Kubernetes | 生产环境、大规模 | 高可用、易扩展、自动化 | 学习成本高 | ⭐⭐⭐⭐⭐ |
| Docker Compose | 开发测试、小规模 | 简单快速、易于理解 | 功能有限 | ⭐⭐⭐⭐ |
| 传统部署 | 特殊环境、遗留系统 | 灵活控制、无依赖 | 维护复杂 | ⭐⭐ |
| 云服务 | 快速上线、弹性需求 | 免运维、快速扩展 | 成本高、依赖云厂商 | ⭐⭐⭐⭐ |

## 2. 环境要求

### 2.1 最低配置要求

#### 2.1.1 单节点部署
```yaml
# 最低配置（开发/测试环境）
CPU: 4核
内存: 16GB
存储: 100GB SSD
网络: 100Mbps带宽
操作系统: Ubuntu 20.04 LTS / CentOS 8
```

#### 2.1.2 生产环境推荐配置
```yaml
# 推荐配置（生产环境）
应用服务器:
  - CPU: 8核
  - 内存: 32GB
  - 存储: 500GB SSD
  - 数量: 3台

数据库服务器:
  - CPU: 16核
  - 内存: 64GB
  - 存储: 1TB SSD + 2TB HDD（备份）
  - 数量: 2台（主从）

负载均衡器:
  - CPU: 4核
  - 内存: 8GB
  - 数量: 2台（高可用）

网络要求:
  - 带宽: 1Gbps
  - 延迟: < 10ms（内网）
  - 防火墙: 开放必要端口
```

### 2.2 软件依赖

#### 2.2.1 基础软件
```bash
# 操作系统依赖
- Docker 20.10+
- Docker Compose 2.0+
- Kubernetes 1.25+ (可选)
- Helm 3.0+ (可选)

# 数据库软件
- PostgreSQL 14+
- Redis 7+
- Elasticsearch 8+
- Qdrant 1.4+
- MinIO RELEASE.2023-12-01T19-33-25Z+

# 中间件软件
- Nginx 1.20+
- Kong Gateway 3.0+
- RabbitMQ 3.11+ (可选)
- Prometheus 2.40+ (监控)
- Grafana 9.0+ (监控)
```

#### 2.2.2 开发工具
```bash
# 必需工具
- Git 2.30+
- Make 4.0+
- curl 7.70+
- jq 1.6+ (JSON处理)

# 容器工具
- kubectl 1.25+ (K8s部署)
- helm 3.0+ (K8s包管理)
- k9s (K8s管理界面)

# 数据库工具
- psql (PostgreSQL客户端)
- redis-cli (Redis客户端)
```

## 3. 容器化部署（推荐）

### 3.1 Docker Compose部署

#### 3.1.1 环境准备
```bash
# 1. 安装Docker
curl -fsSL https://get.docker.com | sh
sudo usermod -aG docker $USER

# 2. 安装Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# 3. 验证安装
docker --version
docker-compose --version
```

#### 3.1.2 下载部署包
```bash
# 克隆项目仓库
git clone https://github.com/your-org/fin-pre-assist.git
cd fin-pre-assist

# 切换到稳定版本
git checkout v1.2.0

# 进入部署目录
cd deployment/docker-compose
```

#### 3.1.3 配置环境变量
```bash
# 复制环境变量模板
cp .env.example .env

# 编辑环境变量
vim .env
```

**环境变量配置示例**:
```bash
# 基础配置
COMPOSE_PROJECT_NAME=fin-pre-assist
ENVIRONMENT=production
DOMAIN=api.fin-pre-assist.com

# 数据库配置
POSTGRES_DB=fin_pre_assist
POSTGRES_USER=finpreassist
POSTGRES_PASSWORD=your_secure_password
DATABASE_URL=postgresql://finpreassist:your_secure_password@postgres:5432/fin_pre_assist

# Redis配置
REDIS_URL=redis://redis:6379/0
REDIS_PASSWORD=your_redis_password

# JWT密钥
SECRET_KEY=your_very_long_and_secure_secret_key
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# AI服务配置
OPENAI_API_KEY=your_openai_api_key
HUGGINGFACE_API_KEY=your_huggingface_api_key

# 存储配置
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin123
MINIO_ENDPOINT=http://minio:9000
MINIO_BUCKET_NAME=fin-pre-assist

# 邮件配置
SMTP_SERVER=smtp.example.com
SMTP_PORT=587
SMTP_USERNAME=noreply@fin-pre-assist.com
SMTP_PASSWORD=your_smtp_password
```

#### 3.1.4 启动服务
```bash
# 1. 拉取镜像
docker-compose pull

# 2. 启动基础设施服务（数据库等）
docker-compose up -d postgres redis elasticsearch qdrant minio

# 3. 等待数据库初始化（约30秒）
sleep 30

# 4. 启动应用服务
docker-compose up -d backend frontend nginx

# 5. 验证服务状态
docker-compose ps
```

#### 3.1.5 服务验证
```bash
# 检查服务状态
curl -f http://localhost/health || echo "Service not ready"

# 检查数据库连接
docker-compose exec postgres psql -U finpreassist -d fin_pre_assist -c "SELECT version();"

# 检查Redis连接
docker-compose exec redis redis-cli ping

# 检查Elasticsearch
curl -f http://localhost:9200/_cluster/health || echo "Elasticsearch not ready"

# 查看日志
docker-compose logs -f backend
```

### 3.2 Kubernetes部署

#### 3.2.1 集群准备
```bash
# 1. 安装kubectl
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

# 2. 安装Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# 3. 配置kubeconfig（根据你的集群提供商）
# 例如，对于AWS EKS:
aws eks update-kubeconfig --region us-west-2 --name fin-pre-assist-cluster
```

#### 3.2.2 创建命名空间
```bash
# 创建专用命名空间
kubectl create namespace fin-pre-assist

# 设置默认命名空间
kubectl config set-context --current --namespace=fin-pre-assist
```

#### 3.2.3 配置存储
```bash
# 创建StorageClass（如果使用动态存储）
kubectl apply -f - <<EOF
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast-ssd
provisioner: kubernetes.io/aws-ebs  # 根据你的环境调整
parameters:
  type: gp3
  fsType: ext4
allowVolumeExpansion: true
EOF

# 创建持久卷声明模板
kubectl apply -f - <<EOF
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-data
  namespace: fin-pre-assist
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: fast-ssd
  resources:
    requests:
      storage: 100Gi
EOF
```

#### 3.2.4 配置ConfigMap和Secret
```bash
# 创建ConfigMap
kubectl create configmap app-config \
  --from-literal=database.url=postgresql://postgres:5432/fin_pre_assist \
  --from-literal=redis.url=redis://redis:6379 \
  --from-literal=elasticsearch.url=http://elasticsearch:9200 \
  --namespace=fin-pre-assist

# 创建Secret
kubectl create secret generic app-secrets \
  --from-literal=database.password=your_secure_password \
  --from-literal=redis.password=your_redis_password \
  --from-literal=jwt.secret=your_jwt_secret \
  --from-literal=openai.api_key=your_openai_key \
  --namespace=fin-pre-assist
```

#### 3.2.5 使用Helm部署
```bash
# 添加Helm仓库
helm repo add fin-pre-assist https://helm.fin-pre-assist.com
helm repo update

# 创建values.yaml文件
cat > values.yaml <<EOF
image:
  repository: fin-pre-assist
  tag: v1.2.0
  pullPolicy: IfNotPresent

replicaCount: 3

service:
  type: ClusterIP
  port: 8000

ingress:
  enabled: true
  className: nginx
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  hosts:
    - host: api.fin-pre-assist.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: fin-pre-assist-tls
      hosts:
        - api.fin-pre-assist.com

resources:
  limits:
    cpu: 1000m
    memory: 2Gi
  requests:
    cpu: 250m
    memory: 512Mi

autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

persistence:
  enabled: true
  storageClass: "fast-ssd"
  size: 100Gi

postgresql:
  enabled: true
  auth:
    postgresPassword: "your_postgres_password"
    database: "fin_pre_assist"
  primary:
    persistence:
      size: 100Gi

redis:
  enabled: true
  auth:
    enabled: true
    password: "your_redis_password"
  master:
    persistence:
      size: 10Gi

elasticsearch:
  enabled: true
  minimumMasterNodes: 1
  replicas: 1
EOF

# 安装应用
helm install fin-pre-assist fin-pre-assist/fin-pre-assist \
  -f values.yaml \
  --namespace fin-pre-assist \
  --create-namespace \
  --version 1.2.0

# 验证安装
helm status fin-pre-assist -n fin-pre-assist
kubectl get pods -n fin-pre-assist
```

#### 3.2.6 验证部署
```bash
# 检查Pod状态
kubectl get pods -n fin-pre-assist

# 检查服务状态
kubectl get svc -n fin-pre-assist

# 检查Ingress
kubectl get ingress -n fin-pre-assist

# 查看应用日志
kubectl logs -f deployment/fin-pre-assist-backend -n fin-pre-assist

# 测试API端点
curl -f https://api.fin-pre-assist.com/health || echo "Service not ready"
```

## 4. 传统部署方式

### 4.1 环境准备

#### 4.1.1 系统初始化
```bash
# 1. 更新系统
sudo apt update && sudo apt upgrade -y  # Ubuntu/Debian
# 或
sudo yum update -y  # CentOS/RHEL

# 2. 安装基础工具
sudo apt install -y curl wget git vim htop net-tools  # Ubuntu/Debian
# 或
sudo yum install -y curl wget git vim htop net-tools  # CentOS/RHEL

# 3. 配置防火墙
sudo ufw allow 22/tcp
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
sudo ufw enable

# 4. 创建专用用户
sudo useradd -m -s /bin/bash finpreassist
sudo usermod -aG sudo finpreassist
```

#### 4.1.2 安装运行时环境
```bash
# 安装Python 3.11
sudo apt install -y software-properties-common
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt install -y python3.11 python3.11-venv python3.11-dev

# 安装Node.js 18.x
curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
sudo apt install -y nodejs

# 验证安装
python3.11 --version
node --version
npm --version
```

### 4.2 数据库安装

#### 4.2.1 PostgreSQL安装
```bash
# 安装PostgreSQL
sudo apt install -y postgresql postgresql-contrib

# 启动服务
sudo systemctl start postgresql
sudo systemctl enable postgresql

# 创建数据库和用户
sudo -u postgres psql <<EOF
CREATE DATABASE fin_pre_assist;
CREATE USER finpreassist WITH PASSWORD 'your_secure_password';
GRANT ALL PRIVILEGES ON DATABASE fin_pre_assist TO finpreassist;
ALTER USER finpreassist CREATEDB;
EOF

# 配置PostgreSQL
sudo vim /etc/postgresql/14/main/postgresql.conf
# 修改以下配置
listen_addresses = '*'
max_connections = 200
shared_buffers = 256MB
effective_cache_size = 1GB

# 配置访问权限
sudo vim /etc/postgresql/14/main/pg_hba.conf
# 添加
host    fin_pre_assist    finpreassist    0.0.0.0/0    md5

# 重启服务
sudo systemctl restart postgresql
```

#### 4.2.2 Redis安装
```bash
# 安装Redis
sudo apt install -y redis-server

# 配置Redis
sudo vim /etc/redis/redis.conf
# 修改以下配置
bind 0.0.0.0
requirepass your_redis_password
maxmemory 1gb
maxmemory-policy allkeys-lru

# 启动服务
sudo systemctl start redis-server
sudo systemctl enable redis-server

# 验证连接
redis-cli ping
redis-cli AUTH your_redis_password
```

#### 4.2.3 Elasticsearch安装
```bash
# 导入Elasticsearch GPG密钥
wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -

# 添加Elasticsearch仓库
echo "deb https://artifacts.elastic.co/packages/8.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-8.x.list

# 安装Elasticsearch
sudo apt update
sudo apt install -y elasticsearch

# 配置Elasticsearch
sudo vim /etc/elasticsearch/elasticsearch.yml
# 修改以下配置
cluster.name: fin-pre-assist
node.name: node-1
network.host: 0.0.0.0
http.port: 9200
discovery.type: single-node
xpack.security.enabled: false

# 启动服务
sudo systemctl start elasticsearch
sudo systemctl enable elasticsearch

# 验证服务
curl -X GET "localhost:9200/_cluster/health?pretty"
```

### 4.3 应用部署

#### 4.3.1 后端部署
```bash
# 1. 创建虚拟环境
sudo -u finpreassist python3.11 -m venv /home/finpreassist/backend/venv
source /home/finpreassist/backend/venv/bin/activate

# 2. 安装依赖
cd /home/finpreassist/backend
pip install -r requirements.txt

# 3. 配置应用
vim config.py
# 添加数据库连接等配置

# 4. 数据库迁移
python manage.py db upgrade

# 5. 创建系统服务
sudo tee /etc/systemd/system/fin-pre-assist-backend.service > /dev/null <<EOF
[Unit]
Description=Fin Pre Assist Backend
After=network.target postgresql.service redis.service

[Service]
Type=notify
User=finpreassist
Group=finpreassist
WorkingDirectory=/home/finpreassist/backend
Environment=PATH=/home/finpreassist/backend/venv/bin
ExecStart=/home/finpreassist/backend/venv/bin/uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
ExecReload=/bin/kill -s HUP $MAINPID
KillMode=mixed
TimeoutStopSec=5
PrivateTmp=true

[Install]
WantedBy=multi-user.target
EOF

# 6. 启动服务
sudo systemctl daemon-reload
sudo systemctl start fin-pre-assist-backend
sudo systemctl enable fin-pre-assist-backend

# 7. 验证服务
curl -f http://localhost:8000/health || echo "Backend not ready"
```

#### 4.3.2 前端部署
```bash
# 1. 构建前端
npm install
npm run build

# 2. 配置Nginx
sudo tee /etc/nginx/sites-available/fin-pre-assist > /dev/null <<EOF
server {
    listen 80;
    server_name your-domain.com;
    return 301 https://\$server_name\$request_uri;
}

server {
    listen 443 ssl http2;
    server_name your-domain.com;

    ssl_certificate /etc/ssl/certs/your-domain.crt;
    ssl_certificate_key /etc/ssl/private/your-domain.key;

    # 前端静态文件
    location / {
        root /var/www/fin-pre-assist;
        try_files \$uri \$uri/ /index.html;
        expires 1d;
        add_header Cache-Control "public, immutable";
    }

    # API代理
    location /api/ {
        proxy_pass http://localhost:8000/;
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto \$scheme;

        # WebSocket支持
        proxy_http_version 1.1;
        proxy_set_header Upgrade \$http_upgrade;
        proxy_set_header Connection "upgrade";
    }

    # 健康检查
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
}
EOF

# 3. 启用站点
sudo ln -s /etc/nginx/sites-available/fin-pre-assist /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl reload nginx
```

## 5. 云服务部署

### 5.1 AWS部署

#### 5.1.1 基础设施设置
```bash
# 1. 创建VPC和子网
aws ec2 create-vpc --cidr-block 10.0.0.0/16
aws ec2 create-subnet --vpc-id vpc-xxx --cidr-block 10.0.1.0/24
aws ec2 create-subnet --vpc-id vpc-xxx --cidr-block 10.0.2.0/24

# 2. 创建安全组
aws ec2 create-security-group \
  --group-name fin-pre-assist-sg \
  --description "Security group for Fin Pre Assist"

# 3. 配置安全组规则
aws ec2 authorize-security-group-ingress \
  --group-id sg-xxx \
  --protocol tcp \
  --port 80 \
  --cidr 0.0.0.0/0

aws ec2 authorize-security-group-ingress \
  --group-id sg-xxx \
  --protocol tcp \
  --port 443 \
  --cidr 0.0.0.0/0

# 4. 创建RDS数据库
aws rds create-db-instance \
  --db-instance-identifier fin-pre-assist-db \
  --db-instance-class db.t3.medium \
  --engine postgres \
  --master-username finpreassist \
  --master-user-password your_password \
  --allocated-storage 100 \
  --vpc-security-group-ids sg-xxx

# 5. 创建ElastiCache Redis
aws elasticache create-cache-cluster \
  --cache-cluster-id fin-pre-assist-redis \
  --cache-node-type cache.t3.micro \
  --engine redis \
  --num-cache-nodes 1 \
  --security-group-ids sg-xxx
```

#### 5.1.2 EKS集群部署
```bash
# 1. 创建EKS集群
eksctl create cluster \
  --name fin-pre-assist-cluster \
  --region us-west-2 \
  --nodegroup-name standard-workers \
  --node-type t3.medium \
  --nodes 3 \
  --nodes-min 1 \
  --nodes-max 10 \
  --managed

# 2. 配置kubectl
aws eks update-kubeconfig --region us-west-2 --name fin-pre-assist-cluster

# 3. 安装AWS Load Balancer Controller
kubectl apply -k "github.com/aws/eks-charts/stable/aws-load-balancer-controller/crds?ref=master"

# 4. 安装Cluster Autoscaler
kubectl apply -f https://raw.githubusercontent.com/kubernetes/autoscaler/master/cluster-autoscaler/cloudprovider/aws/examples/cluster-autoscaler-autodiscover.yaml
```

### 5.2 阿里云部署

#### 5.2.1 容器服务ACK
```bash
# 1. 创建ACK集群
aliyun cs CreateCluster \
  --name fin-pre-assist-cluster \
  --region cn-hangzhou \
  --cluster-type Kubernetes \
  --vpc-id vpc-xxx \
  --vswitch-ids vsw-xxx,vsw-yyy \
  --key-pair keypair-xxx

# 2. 配置kubectl
aliyun cs GetClusterCredentials --cluster-id cxxx

# 3. 创建NAS存储
aliyun nas CreateFileSystem \
  --region cn-hangzhou \
  --protocol-type NFS

# 4. 创建RDS数据库
aliyun rds CreateDBInstance \
  --RegionId cn-hangzhou \
  --Engine PostgreSQL \
  --EngineVersion 14.0 \
  --DBInstanceClass rds.pg.s2.large \
  --DBInstanceStorage 100
```

#### 5.2.2 部署应用
```bash
# 1. 创建存储类
kubectl apply -f - <<EOF
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: alicloud-nas
provisioner: nasplugin.csi.alibabacloud.com
parameters:
  server: "xxx.cn-hangzhou.nas.aliyuncs.com"
  path: "/"
EOF

# 2. 部署应用
helm install fin-pre-assist ./helm-chart \
  --namespace fin-pre-assist \
  --set persistence.storageClass=alicloud-nas \
  --set postgresql.enabled=false \
  --set externalDatabase.host=rds-xxx.mysql.rds.aliyuncs.com
```

## 6. 配置与优化

### 6.1 性能优化

#### 6.1.1 数据库优化
```sql
-- PostgreSQL性能优化配置
-- postgresql.conf
shared_buffers = 8GB                  # 25% of RAM
effective_cache_size = 24GB           # 75% of RAM
work_mem = 64MB                       # RAM / max_connections / 2
maintenance_work_mem = 1GB            # RAM / 16
wal_buffers = 256MB                   # shared_buffers / 32
checkpoint_completion_target = 0.9
random_page_cost = 1.1
effective_io_concurrency = 200

-- 连接池优化
max_connections = 200
connection_pool_size = 50
connection_pool_max_overflow = 100
```

#### 6.1.2 Redis优化
```bash
# redis.conf
maxmemory 4gb
maxmemory-policy allkeys-lru
tcp-keepalive 300
timeout 0
tcp-backlog 511

# 持久化优化
save 900 1
save 300 10
save 60 10000
rdbcompression yes
rdbchecksum yes

# 集群配置（如果需要）
cluster-enabled yes
cluster-config-file nodes-6379.conf
cluster-node-timeout 15000
```

#### 6.1.3 应用优化
```python
# FastAPI性能优化
# config.py
APP_CONFIG = {
    # Gunicorn配置
    "workers": 4,                    # CPU核心数 * 2 + 1
    "worker_class": "uvicorn.workers.UvicornWorker",
    "worker_connections": 1000,
    "max_requests": 1000,
    "max_requests_jitter": 50,
    "timeout": 30,
    "keepalive": 2,

    # 数据库连接池
    "db_pool_size": 20,
    "db_max_overflow": 40,
    "db_pool_timeout": 30,
    "db_pool_recycle": 3600,

    # 缓存配置
    "cache_ttl": 3600,
    "cache_max_size": 10000,

    # 异步配置
    "async_pool_size": 10,
    "async_max_workers": 20
}
```

### 6.2 安全配置

#### 6.2.1 网络安全
```yaml
# 防火墙规则（iptables）
# 允许必要端口
-A INPUT -p tcp --dport 22 -j ACCEPT      # SSH
-A INPUT -p tcp --dport 80 -j ACCEPT      # HTTP
-A INPUT -p tcp --dport 443 -j ACCEPT     # HTTPS
-A INPUT -p tcp --dport 5432 -j ACCEPT    # PostgreSQL（仅限内网）
-A INPUT -p tcp --dport 6379 -j ACCEPT    # Redis（仅限内网）
-A INPUT -p tcp --dport 9200 -j ACCEPT    # Elasticsearch（仅限内网）

# 限制连接频率
-A INPUT -p tcp --dport 22 -m state --state NEW -m recent --set
-A INPUT -p tcp --dport 22 -m state --state NEW -m recent --update --seconds 60 --hitcount 4 -j DROP

# 防止DDoS
-A INPUT -p tcp --dport 80 -m limit --limit 25/minute --limit-burst 100 -j ACCEPT
-A INPUT -p tcp --dport 443 -m limit --limit 25/minute --limit-burst 100 -j ACCEPT
```

#### 6.2.2 SSL/TLS配置
```nginx
# Nginx SSL配置
server {
    listen 443 ssl http2;
    server_name api.fin-pre-assist.com;

    # SSL证书
    ssl_certificate /etc/ssl/certs/cert.pem;
    ssl_certificate_key /etc/ssl/private/key.pem;

    # SSL安全配置
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;

    # HSTS
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

    # 其他安全头
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Referrer-Policy "strict-origin-when-cross-origin";
}
```

#### 6.2.3 应用安全
```python
# 应用安全配置
SECURITY_CONFIG = {
    # JWT配置
    "jwt_secret": os.getenv("JWT_SECRET"),
    "jwt_algorithm": "HS256",
    "jwt_expiration": 3600,  # 1小时
    "jwt_refresh_expiration": 604800,  # 7天

    # 密码策略
    "password_min_length": 8,
    "password_require_uppercase": True,
    "password_require_lowercase": True,
    "password_require_digits": True,
    "password_require_special": True,

    # 速率限制
    "rate_limit_default": "100/minute",
    "rate_limit_auth": "10/minute",
    "rate_limit_upload": "20/hour",

    # CORS配置
    "cors_origins": [
        "https://app.fin-pre-assist.com",
        "https://admin.fin-pre-assist.com"
    ],
    "cors_methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    "cors_headers": ["*"],

    # 内容安全
    "max_file_size": 10 * 1024 * 1024,  # 10MB
    "allowed_file_types": [
        "pdf", "docx", "xlsx", "pptx",
        "jpg", "jpeg", "png", "gif"
    ]
}
```

### 6.3 监控配置

#### 6.3.1 Prometheus配置
```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  # 应用指标
  - job_name: 'fin-pre-assist-backend'
    static_configs:
      - targets: ['backend:8000']
    metrics_path: '/metrics'
    scrape_interval: 30s

  # 数据库指标
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  # Redis指标
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  # 系统指标
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
```

#### 6.3.2 告警规则
```yaml
# alert_rules.yml
groups:
- name: fin-pre-assist-alerts
  rules:
  # 高CPU使用率
  - alert: HighCPUUsage
    expr: cpu_usage_percent > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High CPU usage detected"
      description: "CPU usage is above 80% for more than 5 minutes"

  # 高内存使用率
  - alert: HighMemoryUsage
    expr: memory_usage_percent > 85
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High memory usage detected"
      description: "Memory usage is above 85% for more than 5 minutes"

  # 数据库连接数过高
  - alert: HighDBConnections
    expr: pg_stat_activity_count > 150
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "High database connections"
      description: "Database has more than 150 active connections"

  # 应用响应时间过长
  - alert: HighResponseTime
    expr: http_request_duration_seconds{quantile="0.95"} > 2
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High response time"
      description: "95th percentile response time is above 2 seconds"

  # 错误率过高
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High error rate"
      description: "Error rate is above 10% for more than 5 minutes"
```

#### 6.3.3 Grafana仪表板
```json
{
  "dashboard": {
    "title": "Fin Pre Assist System Overview",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{status}}"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, http_request_duration_seconds_bucket)",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.50, http_request_duration_seconds_bucket)",
            "legendFormat": "50th percentile"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m])",
            "legendFormat": "5xx errors"
          }
        ]
      },
      {
        "title": "Database Connections",
        "type": "graph",
        "targets": [
          {
            "expr": "pg_stat_activity_count",
            "legendFormat": "Active connections"
          }
        ]
      },
      {
        "title": "Cache Hit Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "redis_keyspace_hits/(redis_keyspace_hits+redis_keyspace_misses)",
            "legendFormat": "Hit rate"
          }
        ]
      }
    ]
  }
}
```

## 7. 故障排除

### 7.1 常见问题

#### 7.1.1 数据库连接失败
```bash
# 问题诊断
sudo systemctl status postgresql
sudo tail -f /var/log/postgresql/postgresql-14-main.log

# 解决方案
# 1. 检查服务状态
sudo systemctl restart postgresql

# 2. 检查配置
sudo vim /etc/postgresql/14/main/postgresql.conf
sudo vim /etc/postgresql/14/main/pg_hba.conf

# 3. 检查端口
sudo netstat -tlnp | grep 5432

# 4. 测试连接
psql -h localhost -U finpreassist -d fin_pre_assist
```

#### 7.1.2 Redis连接失败
```bash
# 问题诊断
sudo systemctl status redis-server
redis-cli ping

# 解决方案
# 1. 检查配置文件
sudo vim /etc/redis/redis.conf
# 确保 bind 和 requirepass 配置正确

# 2. 重启服务
sudo systemctl restart redis-server

# 3. 测试连接
redis-cli -a your_redis_password ping
```

#### 7.1.3 应用启动失败
```bash
# 查看日志
docker-compose logs backend
# 或
sudo journalctl -u fin-pre-assist-backend -f

# 常见问题
# 1. 端口冲突
sudo netstat -tlnp | grep 8000

# 2. 依赖缺失
pip install -r requirements.txt

# 3. 配置错误
check config.py or environment variables
```

### 7.2 性能问题

#### 7.2.1 高CPU使用率
```bash
# 监控CPU使用率
top -p $(pgrep -f "python.*app.main")

# 分析慢查询
sudo -u postgres psql fin_pre_assist -c "SELECT query, calls, total_time, mean_time FROM pg_stat_statements ORDER BY mean_time DESC LIMIT 10;"

# 检查Redis命令slowlog
redis-cli -a your_redis_password slowlog get 10
```

#### 7.2.2 内存不足
```bash
# 监控内存使用
free -h
vmstat 1 10

# 检查内存泄漏
ps aux --sort=-%mem | head -20

# 优化内存配置
# 减少worker数量
# 调整缓存大小
# 增加SWAP空间
```

#### 7.2.3 磁盘空间不足
```bash
# 检查磁盘使用
df -h
du -sh /var/log/*

# 清理日志
find /var/log -name "*.log" -mtime +7 -delete

# 清理Docker
sudo docker system prune -a

# 数据库清理
sudo -u postgres vacuumdb -z fin_pre_assist
```

### 7.3 网络问题

#### 7.3.1 服务无法访问
```bash
# 检查服务状态
sudo systemctl status fin-pre-assist-backend
curl -I http://localhost:8000/health

# 检查防火墙
sudo ufw status
sudo iptables -L -n

# 检查DNS解析
nslookup your-domain.com
dig your-domain.com
```

#### 7.3.2 SSL证书问题
```bash
# 检查证书有效性
openssl x509 -in /etc/ssl/certs/cert.pem -text -noout

# 检查证书过期时间
openssl x509 -in /etc/ssl/certs/cert.pem -noout -dates

# 更新证书（Let's Encrypt）
certbot renew --dry-run
```

## 8. 升级与迁移

### 8.1 版本升级

#### 8.1.1 滚动升级策略
```bash
# 1. 备份数据
docker-compose exec postgres pg_dump -U finpreassist fin_pre_assist > backup_$(date +%Y%m%d).sql

# 2. 拉取新镜像
docker-compose pull

# 3. 逐个升级服务
docker-compose up -d postgres redis elasticsearch  # 基础设施
docker-compose up -d backend                       # 后端服务
docker-compose up -d frontend                      # 前端服务

# 4. 验证升级
curl -f http://localhost/health
docker-compose logs backend | tail -50
```

#### 8.1.2 数据库迁移
```bash
# 1. 创建迁移脚本
# migrations/v1.1.0_to_v1.2.0.sql

# 2. 备份数据库
docker-compose exec postgres pg_dump -U finpreassist fin_pre_assist > pre_migration_backup.sql

# 3. 执行迁移
docker-compose exec postgres psql -U finpreassist -d fin_pre_assist -f /migrations/v1.1.0_to_v1.2.0.sql

# 4. 验证迁移
# 检查数据完整性
# 运行测试用例
```

### 8.2 数据迁移

#### 8.2.1 环境间迁移
```bash
#!/bin/bash
# 数据迁移脚本

# 源环境配置
SOURCE_DB_HOST=source-db.example.com
SOURCE_DB_NAME=fin_pre_assist
SOURCE_DB_USER=postgres

# 目标环境配置
TARGET_DB_HOST=target-db.example.com
TARGET_DB_NAME=fin_pre_assist
TARGET_DB_USER=postgres

# 1. 导出数据
echo "Exporting data from source database..."
pg_dump -h $SOURCE_DB_HOST -U $SOURCE_DB_USER -d $SOURCE_DB_NAME \
  --format=custom \
  --verbose \
  --file=fin_pre_assist_export.dump

# 2. 传输数据
echo "Transferring data to target environment..."
scp fin_pre_assist_export.dump user@target-server:/tmp/

# 3. 导入数据
echo "Importing data to target database..."
ssh user@target-server "pg_restore -h $TARGET_DB_HOST -U $TARGET_DB_USER -d $TARGET_DB_NAME /tmp/fin_pre_assist_export.dump"

# 4. 验证数据
echo "Verifying data migration..."
ssh user@target-server "psql -h $TARGET_DB_HOST -U $TARGET_DB_USER -d $TARGET_DB_NAME -c 'SELECT count(*) FROM users;'"

echo "Migration completed!"
```

#### 8.2.2 零停机迁移
```yaml
# Kubernetes零停机迁移策略
apiVersion: v1
kind: Service
metadata:
  name: fin-pre-assist-service
spec:
  selector:
    app: fin-pre-assist
    version: v1  # 通过label控制版本
  ports:
  - port: 80
    targetPort: 8000
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fin-pre-assist-v2
spec:
  replicas: 3
  selector:
    matchLabels:
      app: fin-pre-assist
      version: v2
  template:
    metadata:
      labels:
        app: fin-pre-assist
        version: v2
    spec:
      containers:
      - name: backend
        image: fin-pre-assist/backend:v1.2.0
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          value: "postgresql://new-db:5432/fin_pre_assist"
```

## 9. 运维自动化

### 9.1 CI/CD配置

#### 9.1.1 GitHub Actions
```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install -r requirements-test.txt
    - name: Run tests
      run: pytest tests/ -v --cov=app

  build:
    needs: test
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Build Docker image
      run: |
        docker build -t fin-pre-assist/backend:${{ github.sha }} .
        docker tag fin-pre-assist/backend:${{ github.sha }} fin-pre-assist/backend:latest
    - name: Push to registry
      run: |
        echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin
        docker push fin-pre-assist/backend:${{ github.sha }}
        docker push fin-pre-assist/backend:latest

  deploy:
    needs: build
    runs-on: ubuntu-latest
    steps:
    - name: Deploy to Kubernetes
      uses: azure/k8s-deploy@v1
      with:
        manifests: |
          k8s/deployment.yaml
          k8s/service.yaml
        images: |
          fin-pre-assist/backend:${{ github.sha }}
```

#### 9.1.2 GitLab CI
```yaml
# .gitlab-ci.yml
stages:
  - test
  - build
  - deploy

variables:
  DOCKER_REGISTRY: registry.gitlab.com
  IMAGE_NAME: $DOCKER_REGISTRY/$CI_PROJECT_PATH

before_script:
  - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY

test:
  stage: test
  image: python:3.11
  script:
    - pip install -r requirements.txt
    - pip install -r requirements-test.txt
    - pytest tests/ -v --cov=app --cov-report=xml
    - coverage report
  coverage: '/TOTAL.+ ([0-9]{1,3}%)/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml

build:
  stage: build
  image: docker:latest
  services:
    - docker:dind
  script:
    - docker build -t $IMAGE_NAME:$CI_COMMIT_SHA .
    - docker tag $IMAGE_NAME:$CI_COMMIT_SHA $IMAGE_NAME:latest
    - docker push $IMAGE_NAME:$CI_COMMIT_SHA
    - docker push $IMAGE_NAME:latest
  only:
    - main

deploy:
  stage: deploy
  image: bitnami/kubectl:latest
  script:
    - kubectl config use-context production
    - kubectl set image deployment/fin-pre-assist-backend backend=$IMAGE_NAME:$CI_COMMIT_SHA -n fin-pre-assist
    - kubectl rollout status deployment/fin-pre-assist-backend -n fin-pre-assist
  only:
    - main
  when: manual
```

### 9.2 监控告警

#### 9.2.1 自动化监控
```python
#!/usr/bin/env python3
# monitoring/health_check.py

import requests
import smtplib
from email.mime.text import MIMEText
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class HealthChecker:
    def __init__(self, endpoints, email_config):
        self.endpoints = endpoints
        self.email_config = email_config

    def check_health(self):
        """检查所有服务端点"""
        alerts = []

        for endpoint in self.endpoints:
            try:
                response = requests.get(
                    endpoint['url'],
                    timeout=endpoint.get('timeout', 10)
                )

                if response.status_code != 200:
                    alerts.append({
                        'endpoint': endpoint['name'],
                        'status': response.status_code,
                        'message': 'Service returned non-200 status'
                    })

            except requests.exceptions.RequestException as e:
                alerts.append({
                    'endpoint': endpoint['name'],
                    'status': 'ERROR',
                    'message': str(e)
                })

        return alerts

    def send_alert(self, alerts):
        """发送告警邮件"""
        if not alerts:
            return

        subject = f"Fin Pre Assist Health Alert - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        body = self.format_alert_message(alerts)

        msg = MIMEText(body)
        msg['Subject'] = subject
        msg['From'] = self.email_config['from']
        msg['To'] = ', '.join(self.email_config['to'])

        try:
            with smtplib.SMTP(self.email_config['smtp_server'], self.email_config['smtp_port']) as server:
                server.starttls()
                server.login(self.email_config['username'], self.email_config['password'])
                server.send_message(msg)

            logger.info(f"Alert email sent successfully")
        except Exception as e:
            logger.error(f"Failed to send alert email: {e}")

    def format_alert_message(self, alerts):
        """格式化告警消息"""
        message = "The following services are experiencing issues:\n\n"

        for alert in alerts:
            message += f"Service: {alert['endpoint']}\n"
            message += f"Status: {alert['status']}\n"
            message += f"Message: {alert['message']}\n"
            message += "-" * 50 + "\n\n"

        message += "Please check the system immediately.\n"
        return message

if __name__ == "__main__":
    # 配置检查端点
    endpoints = [
        {
            'name': 'Backend API',
            'url': 'https://api.fin-pre-assist.com/health',
            'timeout': 10
        },
        {
            'name': 'Frontend',
            'url': 'https://app.fin-pre-assist.com/health',
            'timeout': 10
        },
        {
            'name': 'Database',
            'url': 'https://api.fin-pre-assist.com/health/db',
            'timeout': 5
        }
    ]

    # 邮件配置
    email_config = {
        'smtp_server': 'smtp.example.com',
        'smtp_port': 587,
        'username': 'alerts@example.com',
        'password': 'email_password',
        'from': 'alerts@example.com',
        'to': ['admin@example.com', 'devops@example.com']
    }

    checker = HealthChecker(endpoints, email_config)
    alerts = checker.check_health()

    if alerts:
        checker.send_alert(alerts)
        logger.warning(f"Found {len(alerts)} service issues")
    else:
        logger.info("All services are healthy")
```

#### 9.2.2 自动化备份
```bash
#!/bin/bash
# backup/automated_backup.sh

set -e

# 配置
BACKUP_DIR="/backup/fin-pre-assist"
RETENTION_DAYS=30
S3_BUCKET="fin-pre-assist-backups"
DATE=$(date +%Y%m%d_%H%M%S)

# 创建备份目录
mkdir -p "$BACKUP_DIR"

# 数据库备份
echo "Backing up PostgreSQL database..."
docker exec fin-pre-assist-postgres-1 pg_dump -U finpreassist fin_pre_assist | gzip > "$BACKUP_DIR/db_backup_$DATE.sql.gz"

# 文件备份
echo "Backing up uploaded files..."
tar -czf "$BACKUP_DIR/files_backup_$DATE.tar.gz" -C /var/lib/docker/volumes fin-pre-assist_minio-data

# Redis数据备份
echo "Backing up Redis data..."
docker exec fin-pre-assist-redis-1 redis-cli --rdb /tmp/redis_backup.rdb
docker cp fin-pre-assist-redis-1:/tmp/redis_backup.rdb "$BACKUP_DIR/redis_backup_$DATE.rdb"

# 上传到S3（可选）
if command -v aws &> /dev/null; then
    echo "Uploading to S3..."
    aws s3 sync "$BACKUP_DIR" "s3://$S3_BUCKET/" --exclude "*" --include "*$DATE*"
fi

# 清理旧备份
echo "Cleaning up old backups..."
find "$BACKUP_DIR" -name "*.gz" -type f -mtime +$RETENTION_DAYS -delete
find "$BACKUP_DIR" -name "*.rdb" -type f -mtime +$RETENTION_DAYS -delete

echo "Backup completed successfully: $DATE"
```

## 10. 总结

### 10.1 部署检查清单

#### 10.1.1 部署前检查
- [ ] 硬件资源满足最低要求
- [ ] 操作系统版本兼容
- [ ] 网络配置正确
- [ ] 安全组/防火墙配置
- [ ] SSL证书准备
- [ ] 域名解析配置

#### 10.1.2 部署过程检查
- [ ] 所有服务正常启动
- [ ] 数据库连接成功
- [ ] 缓存服务运行正常
- [ ] 搜索服务可用
- [ ] 文件存储服务正常
- [ ] API接口测试通过
- [ ] 前端页面加载正常

#### 10.1.3 部署后检查
- [ ] 监控告警配置
- [ ] 日志收集配置
- [ ] 备份策略配置
- [ ] 安全配置检查
- [ ] 性能基准测试
- [ ] 灾难恢复测试

### 10.2 最佳实践

#### 10.2.1 高可用性
1. **多实例部署**：关键服务至少部署3个实例
2. **健康检查**：配置完善的健康检查机制
3. **自动故障转移**：数据库主从自动切换
4. **无状态设计**：应用服务无状态，便于扩展
5. **数据备份**：定期备份，异地存储

#### 10.2.2 性能优化
1. **缓存策略**：多级缓存，减少数据库压力
2. **连接池**：合理配置数据库连接池
3. **CDN加速**：静态资源使用CDN
4. **压缩传输**：启用Gzip压缩
5. **图片优化**：图片压缩和格式优化

#### 10.2.3 安全加固
1. **最小权限**：服务使用最小必要权限
2. **网络隔离**：不同服务网络隔离
3. **加密传输**：所有数据传输加密
4. **定期更新**：及时更新安全补丁
5. **访问控制**：严格的访问控制策略

#### 10.2.4 运维自动化
1. **CI/CD流程**：自动化构建和部署
2. **基础设施即代码**：使用代码管理基础设施
3. **监控告警**：完善的监控告警体系
4. **自动扩缩容**：根据负载自动调整资源
5. **日志集中化**：统一日志收集和分析

### 10.3 技术支持

#### 10.3.1 获取帮助
- **官方文档**: https://docs.fin-pre-assist.com
- **GitHub Issues**: https://github.com/your-org/fin-pre-assist/issues
- **技术支持邮箱**: support@fin-pre-assist.com
- **社区论坛**: https://community.fin-pre-assist.com

#### 10.3.2 专业服务
- **部署咨询**: 专业的部署架构设计
- **性能优化**: 系统性能调优服务
- **安全评估**: 安全漏洞扫描和修复
- **培训服务**: 运维团队技术培训

---

**文档结束**

*本安装部署手册为金融售前方案辅助编写系统提供了详细的部署指导，涵盖容器化部署、传统部署、云服务部署等多种方案，确保系统能够稳定、安全、高效地运行。*