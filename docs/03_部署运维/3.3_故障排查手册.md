# é‡‘èå”®å‰æ–¹æ¡ˆè¾…åŠ©ç¼–å†™ç³»ç»Ÿ - æ•…éšœæ’æŸ¥æ‰‹å†Œ

| æ–‡æ¡£ä¿¡æ¯ | å†…å®¹ |
|---------|------|
| **æ–‡æ¡£ç‰ˆæœ¬** | v1.2.0 |
| **å‘å¸ƒæ—¥æœŸ** | 2025-11-08 |
| **ç›®æ ‡è¯»è€…** | è¿ç»´å·¥ç¨‹å¸ˆã€æŠ€æœ¯æ”¯æŒ |
| **æ–‡æ¡£çŠ¶æ€** | æ­£å¼å‘å¸ƒ |

---

## ğŸ“‹ ç›®å½•

1. [æ•…éšœæ’æŸ¥æµç¨‹](#1-æ•…éšœæ’æŸ¥æµç¨‹)
2. [æ•°æ®åº“æ•…éšœ](#2-æ•°æ®åº“æ•…éšœ)
3. [AIæœåŠ¡æ•…éšœ](#3-aiæœåŠ¡æ•…éšœ)
4. [å‘é‡æ•°æ®åº“æ•…éšœ](#4-å‘é‡æ•°æ®åº“æ•…éšœ)
5. [å‰ç«¯æ•…éšœ](#5-å‰ç«¯æ•…éšœ)
6. [æ€§èƒ½é—®é¢˜](#6-æ€§èƒ½é—®é¢˜)
7. [ç½‘ç»œé—®é¢˜](#7-ç½‘ç»œé—®é¢˜)
8. [æ—¥å¿—åˆ†æ](#8-æ—¥å¿—åˆ†æ)

---

## 1. æ•…éšœæ’æŸ¥æµç¨‹

### 1.1 æ ‡å‡†æ’æŸ¥æ­¥éª¤

```
æ­¥éª¤1ï¼šæ”¶é›†æ•…éšœä¿¡æ¯
  â†“
æ­¥éª¤2ï¼šæŸ¥çœ‹æ—¥å¿—æ–‡ä»¶
  â†“
æ­¥éª¤3ï¼šæ£€æŸ¥æœåŠ¡çŠ¶æ€
  â†“
æ­¥éª¤4ï¼šå®šä½æ•…éšœç»„ä»¶
  â†“
æ­¥éª¤5ï¼šæ‰§è¡Œä¿®å¤æªæ–½
  â†“
æ­¥éª¤6ï¼šéªŒè¯ä¿®å¤ç»“æœ
  â†“
æ­¥éª¤7ï¼šè®°å½•æ•…éšœå’Œè§£å†³æ–¹æ¡ˆ
```

### 1.2 å¿«é€Ÿè¯Šæ–­å‘½ä»¤

```bash
# æ£€æŸ¥æ‰€æœ‰æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æœ€æ–°æ—¥å¿—
tail -f backend/logs/app.log

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
mysql -h localhost -u root -p -e "SHOW DATABASES;"

# æ£€æŸ¥ç«¯å£å ç”¨
lsof -i :8000  # åç«¯
lsof -i :3000  # å‰ç«¯

# æ£€æŸ¥ç£ç›˜ç©ºé—´
df -h

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
free -m
```

---

## 2. æ•°æ®åº“æ•…éšœ

### æ•…éšœ2.1ï¼šæ•°æ®åº“è¿æ¥å¤±è´¥

**ç—‡çŠ¶**ï¼š
```
ERROR: (pymysql.err.OperationalError) (2003, "Can't connect to MySQL server")
æˆ–
sqlalchemy.exc.OperationalError: could not connect to server
```

**å¯èƒ½åŸå› **ï¼š
1. æ•°æ®åº“æœåŠ¡æœªå¯åŠ¨
2. è¿æ¥é…ç½®é”™è¯¯
3. ç½‘ç»œé—®é¢˜
4. æ•°æ®åº“ç”¨æˆ·æƒé™ä¸è¶³

**æ’æŸ¥æ­¥éª¤**ï¼š

**æ­¥éª¤1ï¼šæ£€æŸ¥æ•°æ®åº“æœåŠ¡çŠ¶æ€**
```bash
# MySQL
sudo systemctl status mysql
# æˆ–
docker ps | grep mysql

# PostgreSQL
sudo systemctl status postgresql
# æˆ–
docker ps | grep postgres
```

**æ­¥éª¤2ï¼šæ£€æŸ¥æ•°æ®åº“é…ç½®**
```bash
# æŸ¥çœ‹.envé…ç½®
cat backend/.env

# æ£€æŸ¥è¿æ¥å­—ç¬¦ä¸²æ ¼å¼
# MySQL: mysql+pymysql://root:root@localhost:3306/regulatory_data_complete
# PostgreSQL: postgresql://postgres:postgres@localhost:5432/fin_pre_assist
```

**æ­¥éª¤3ï¼šæµ‹è¯•æ•°æ®åº“è¿æ¥**
```bash
# MySQL
mysql -h localhost -u root -p
# è¾“å…¥å¯†ç åæ‰§è¡Œ
SHOW DATABASES;
USE regulatory_data_complete;
SHOW TABLES;

# PostgreSQL
psql -h localhost -U postgres -d fin_pre_assist
# æ‰§è¡Œ
\l  # åˆ—å‡ºæ•°æ®åº“
\dt # åˆ—å‡ºè¡¨
```

**æ­¥éª¤4ï¼šæ£€æŸ¥æ•°æ®åº“ç”¨æˆ·æƒé™**
```sql
-- MySQL
GRANT ALL PRIVILEGES ON regulatory_data_complete.* TO 'root'@'localhost';
FLUSH PRIVILEGES;

-- PostgreSQL
GRANT ALL PRIVILEGES ON DATABASE fin_pre_assist TO postgres;
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ1ï¼šå¯åŠ¨æ•°æ®åº“æœåŠ¡**
```bash
# MySQL
sudo systemctl start mysql
# æˆ–
docker-compose up -d mysql

# PostgreSQL
sudo systemctl start postgresql
# æˆ–
docker-compose up -d postgres
```

**æ–¹æ¡ˆ2ï¼šä¿®æ­£é…ç½®æ–‡ä»¶**
```bash
# ç¼–è¾‘backend/.env
nano backend/.env

# ç¡®ä¿é…ç½®æ­£ç¡®
DATABASE_URL=mysql+pymysql://root:root@localhost:3306/regulatory_data_complete

# æˆ–ä½¿ç”¨PostgreSQL
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/fin_pre_assist
```

**æ–¹æ¡ˆ3ï¼šé‡æ–°åˆå§‹åŒ–æ•°æ®åº“**
```bash
cd backend
python init_db.py
```

---

### æ•…éšœ2.2ï¼šæ•°æ®åº“è¡¨ä¸å­˜åœ¨

**ç—‡çŠ¶**ï¼š
```
sqlalchemy.exc.ProgrammingError: (pymysql.err.ProgrammingError) (1146, "Table 'regulatory_data_complete.users' doesn't exist")
```

**åŸå› **ï¼šæ•°æ®åº“æœªåˆå§‹åŒ–æˆ–è¡¨è¢«è¯¯åˆ é™¤

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# è¿è¡Œæ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
cd backend
python init_db.py

# æŸ¥çœ‹è¾“å‡ºç¡®è®¤è¡¨åˆ›å»ºæˆåŠŸ
# è¾“å‡ºåº”åŒ…å«ï¼š
# Creating table: users
# Creating table: documents
# Creating table: proposals
# Creating table: templates
# Creating table: knowledge_base
```

---

### æ•…éšœ2.3ï¼šæ•°æ®åº“è¿æ¥æ± è€—å°½

**ç—‡çŠ¶**ï¼š
```
sqlalchemy.exc.TimeoutError: QueuePool limit of size 5 overflow 10 reached
```

**åŸå› **ï¼š
1. è¿æ¥æœªæ­£ç¡®å…³é—­
2. å¹¶å‘è¯·æ±‚è¿‡å¤š
3. è¿æ¥æ± é…ç½®è¿‡å°

**æ’æŸ¥**ï¼š
```bash
# æŸ¥çœ‹æ•°æ®åº“è¿æ¥æ•°
# MySQL
mysql -u root -p -e "SHOW PROCESSLIST;"

# PostgreSQL
psql -U postgres -c "SELECT * FROM pg_stat_activity;"
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ1ï¼šå¢åŠ è¿æ¥æ± å¤§å°**
```python
# backend/app/core/database.py
engine = create_engine(
    DATABASE_URL,
    pool_size=20,        # å¢åŠ åˆ°20
    max_overflow=40,     # å¢åŠ åˆ°40
    pool_pre_ping=True,
    pool_recycle=3600
)
```

**æ–¹æ¡ˆ2ï¼šç¡®ä¿è¿æ¥æ­£ç¡®å…³é—­**
```python
# ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

---

## 3. AIæœåŠ¡æ•…éšœ

### æ•…éšœ3.1ï¼šæ™ºè°±AIè°ƒç”¨å¤±è´¥

**ç—‡çŠ¶**ï¼š
```
ERROR: æ™ºè°±AIè°ƒç”¨å¤±è´¥: API key is invalid
æˆ–
ERROR: Request failed with status 401
```

**å¯èƒ½åŸå› **ï¼š
1. APIå¯†é’¥æœªé…ç½®æˆ–é”™è¯¯
2. APIå¯†é’¥é¢åº¦ç”¨å®Œ
3. ç½‘ç»œæ— æ³•è®¿é—®æ™ºè°±AIæœåŠ¡å™¨
4. APIå¯†é’¥è¢«ç¦ç”¨

**æ’æŸ¥æ­¥éª¤**ï¼š

**æ­¥éª¤1ï¼šæ£€æŸ¥APIå¯†é’¥é…ç½®**
```bash
# æŸ¥çœ‹.envæ–‡ä»¶
cat backend/.env | grep ZHIPU

# åº”è¯¥çœ‹åˆ°
# ZHIPU_API_KEY=your_api_key_here
```

**æ­¥éª¤2ï¼šéªŒè¯APIå¯†é’¥**
```bash
# è¿è¡Œæµ‹è¯•è„šæœ¬
cd backend
python test_zhipu_api.py

# è¾“å‡ºåº”è¯¥æ˜¯
# âœ“ æ™ºè°±AIè¿æ¥æˆåŠŸ
# âœ“ æ¨¡å‹è¿”å›æ­£å¸¸
```

**æ­¥éª¤3ï¼šæ£€æŸ¥APIé¢åº¦**
```bash
# ç™»å½•æ™ºè°±AIæ§åˆ¶å°
# https://open.bigmodel.cn/
# æŸ¥çœ‹å‰©ä½™é¢åº¦å’Œè°ƒç”¨æ¬¡æ•°
```

**æ­¥éª¤4ï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥**
```bash
# æµ‹è¯•æ˜¯å¦èƒ½è®¿é—®æ™ºè°±AI
curl -I https://open.bigmodel.cn

# åº”è¿”å› HTTP/2 200
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ1ï¼šé…ç½®æ­£ç¡®çš„APIå¯†é’¥**
```bash
# ç¼–è¾‘.envæ–‡ä»¶
nano backend/.env

# è®¾ç½®æ­£ç¡®çš„APIå¯†é’¥
ZHIPU_API_KEY=your_actual_api_key

# é‡å¯åç«¯æœåŠ¡
docker-compose restart backend
```

**æ–¹æ¡ˆ2ï¼šå……å€¼APIé¢åº¦**
```
ç™»å½•æ™ºè°±AIæ§åˆ¶å° â†’ å……å€¼ä¸­å¿ƒ â†’ å……å€¼
```

**æ–¹æ¡ˆ3ï¼šé…ç½®ä»£ç†ï¼ˆå¦‚æœç½‘ç»œå—é™ï¼‰**
```python
# backend/app/services/ai_service.py
import os
os.environ['HTTP_PROXY'] = 'http://your-proxy:port'
os.environ['HTTPS_PROXY'] = 'http://your-proxy:port'
```

---

### æ•…éšœ3.2ï¼šAIç”Ÿæˆè¶…æ—¶

**ç—‡çŠ¶**ï¼š
```
ERROR: AIç”Ÿæˆè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•
æˆ–
TimeoutError: Request timeout after 300 seconds
```

**å¯èƒ½åŸå› **ï¼š
1. ç”Ÿæˆå†…å®¹è¿‡é•¿
2. ç½‘ç»œä¸ç¨³å®š
3. æ™ºè°±AIæœåŠ¡è´Ÿè½½è¿‡é«˜
4. è¶…æ—¶è®¾ç½®è¿‡çŸ­

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ1ï¼šå¢åŠ è¶…æ—¶æ—¶é—´**
```python
# backend/app/services/ai_service.py
response = self.client.chat.completions.create(
    model=self.model,
    messages=messages,
    timeout=600  # å¢åŠ åˆ°600ç§’(10åˆ†é’Ÿ)
)
```

**æ–¹æ¡ˆ2ï¼šåˆ†æ®µç”Ÿæˆ**
```python
# å°†é•¿æ–‡æœ¬åˆ†æˆå¤šä¸ªç« èŠ‚åˆ†åˆ«ç”Ÿæˆ
# è€Œä¸æ˜¯ä¸€æ¬¡æ€§ç”Ÿæˆæ•´ä¸ªæ–¹æ¡ˆ
```

**æ–¹æ¡ˆ3ï¼šé‡è¯•æœºåˆ¶**
```python
from tenacity import retry, stop_after_attempt, wait_fixed

@retry(stop=stop_after_attempt(3), wait=wait_fixed(60))
def generate_with_retry(self, prompt):
    return self.client.chat.completions.create(...)
```

---

### æ•…éšœ3.3ï¼šç”Ÿæˆå†…å®¹è´¨é‡å·®

**ç—‡çŠ¶**ï¼šAIç”Ÿæˆçš„æ–¹æ¡ˆä¸ç¬¦åˆé¢„æœŸã€å†…å®¹ç©ºæ´æˆ–ä¸ç›¸å…³

**å¯èƒ½åŸå› **ï¼š
1. æç¤ºè¯è®¾è®¡ä¸å½“
2. çŸ¥è¯†åº“å†…å®¹ä¸è¶³
3. éœ€æ±‚æè¿°ä¸å¤Ÿè¯¦ç»†
4. æ¨¡å‹å‚æ•°è®¾ç½®ä¸å½“

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ1ï¼šä¼˜åŒ–æç¤ºè¯**
```python
# æä¾›æ›´è¯¦ç»†çš„è§’è‰²è®¾å®šå’Œè¾“å‡ºè¦æ±‚
prompt = f"""
# è§’è‰²
ä½ æ˜¯ä¸€ä½æ‹¥æœ‰10å¹´ç»éªŒçš„é‡‘èè¡Œä¸šå”®å‰è§£å†³æ–¹æ¡ˆä¸“å®¶

# ä»»åŠ¡
ä¸º{customer_name}ç¼–å†™ä¸“ä¸šçš„{project_name}æŠ€æœ¯æ–¹æ¡ˆ

# èƒŒæ™¯
{detailed_background}

# å‚è€ƒææ–™
{similar_proposals}
{knowledge_base}

# è¾“å‡ºè¦æ±‚
1. æ–¹æ¡ˆç»“æ„å®Œæ•´
2. å†…å®¹ä¸“ä¸šè¯¦å®
3. ç¬¦åˆé‡‘èè¡Œä¸šè§„èŒƒ
4. å­—æ•°ä¸å°‘äº3000å­—

# å¼€å§‹ç”Ÿæˆ
"""
```

**æ–¹æ¡ˆ2ï¼šä¸°å¯ŒçŸ¥è¯†åº“**
```bash
# ä¸Šä¼ æ›´å¤šé«˜è´¨é‡å†å²æ–¹æ¡ˆ
# æ·»åŠ äº§å“çŸ¥è¯†æ¡ç›®
# æ·»åŠ è¡Œä¸šæœ€ä½³å®è·µ
```

**æ–¹æ¡ˆ3ï¼šè°ƒæ•´æ¨¡å‹å‚æ•°**
```python
response = self.client.chat.completions.create(
    model="glm-4",
    temperature=0.7,  # é™ä½åˆ›é€ æ€§ï¼Œæé«˜å‡†ç¡®æ€§
    top_p=0.8,        # æ§åˆ¶éšæœºæ€§
    max_tokens=4000   # å¢åŠ æœ€å¤§tokenæ•°
)
```

---

## 4. å‘é‡æ•°æ®åº“æ•…éšœ

### æ•…éšœ4.1ï¼šChromaDBåˆå§‹åŒ–å¤±è´¥

**ç—‡çŠ¶**ï¼š
```
ERROR: Failed to initialize ChromaDB
æˆ–
chromadb.errors.InvalidCollectionException
```

**å¯èƒ½åŸå› **ï¼š
1. ChromaDBæ•°æ®ç›®å½•ä¸å­˜åœ¨æˆ–æ— æƒé™
2. æ•°æ®æ–‡ä»¶æŸå
3. ç‰ˆæœ¬ä¸å…¼å®¹

**æ’æŸ¥**ï¼š
```bash
# æ£€æŸ¥ChromaDBæ•°æ®ç›®å½•
ls -la storage/chroma/

# æ£€æŸ¥æƒé™
ls -ld storage/chroma/

# åº”è¯¥æœ‰è¯»å†™æƒé™
drwxr-xr-x  5 user group  160 Nov  8 10:00 storage/chroma/
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ1ï¼šåˆ›å»ºæ•°æ®ç›®å½•å¹¶è®¾ç½®æƒé™**
```bash
mkdir -p storage/chroma
chmod 755 storage/chroma
chown -R $USER:$USER storage/chroma
```

**æ–¹æ¡ˆ2ï¼šé‡æ–°åˆå§‹åŒ–ChromaDB**
```bash
# å¤‡ä»½æ—§æ•°æ®ï¼ˆå¦‚æœ‰ï¼‰
mv storage/chroma storage/chroma.bak

# é‡æ–°åˆå§‹åŒ–
cd backend
python -c "from app.services.vector_service import VectorService; v = VectorService(); print('ChromaDB initialized')"
```

**æ–¹æ¡ˆ3ï¼šå‡çº§ChromaDBç‰ˆæœ¬**
```bash
pip install --upgrade chromadb
```

---

### æ•…éšœ4.2ï¼šå‘é‡æœç´¢æ€§èƒ½æ…¢

**ç—‡çŠ¶**ï¼šè¯­ä¹‰æœç´¢è€—æ—¶è¶…è¿‡5ç§’

**å¯èƒ½åŸå› **ï¼š
1. å‘é‡æ•°æ®é‡è¿‡å¤§
2. æœªä½¿ç”¨ç´¢å¼•
3. æœåŠ¡å™¨èµ„æºä¸è¶³

**æ’æŸ¥**ï¼š
```python
# æ£€æŸ¥collectionå¤§å°
import chromadb
client = chromadb.PersistentClient(path="./storage/chroma")
collection = client.get_collection("documents")
print(f"Document count: {collection.count()}")
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ1ï¼šä½¿ç”¨HNSWç´¢å¼•**
```python
collection = client.create_collection(
    name="documents",
    metadata={
        "hnsw:space": "cosine",
        "hnsw:construction_ef": 200,
        "hnsw:M": 16
    }
)
```

**æ–¹æ¡ˆ2ï¼šåˆ†æ‰¹æŸ¥è¯¢**
```python
# ä¸è¦ä¸€æ¬¡æŸ¥è¯¢æ‰€æœ‰ï¼Œé™åˆ¶top_k
results = collection.query(
    query_texts=[query],
    n_results=10  # åªè¿”å›Top 10
)
```

**æ–¹æ¡ˆ3ï¼šå®šæœŸæ¸…ç†æ— ç”¨æ•°æ®**
```python
# åˆ é™¤è¿‡æœŸæˆ–æ— ç”¨çš„å‘é‡
collection.delete(
    ids=old_document_ids
)
```

---

## 5. å‰ç«¯æ•…éšœ

### æ•…éšœ5.1ï¼šå‰ç«¯æ— æ³•è®¿é—®

**ç—‡çŠ¶**ï¼šæµè§ˆå™¨è®¿é—®http://localhost:3000æ˜¾ç¤º"æ— æ³•è®¿é—®"

**æ’æŸ¥**ï¼š
```bash
# æ£€æŸ¥å‰ç«¯æœåŠ¡çŠ¶æ€
docker-compose ps frontend
# æˆ–
ps aux | grep node

# æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨
lsof -i :3000

# æŸ¥çœ‹å‰ç«¯æ—¥å¿—
docker-compose logs frontend
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ1ï¼šå¯åŠ¨å‰ç«¯æœåŠ¡**
```bash
# Dockeræ–¹å¼
docker-compose up -d frontend

# æœ¬åœ°æ–¹å¼
cd frontend
npm start
```

**æ–¹æ¡ˆ2ï¼šæ›´æ¢ç«¯å£**
```bash
# ä¿®æ”¹frontend/package.json
"scripts": {
  "start": "PORT=3001 vite"
}
```

---

### æ•…éšœ5.2ï¼šAPIè°ƒç”¨å¤±è´¥

**ç—‡çŠ¶**ï¼šå‰ç«¯æ§åˆ¶å°æ˜¾ç¤º"Network Error"æˆ–"404 Not Found"

**æ’æŸ¥**ï¼š
```javascript
// æ‰“å¼€æµè§ˆå™¨å¼€å‘è€…å·¥å…· â†’ Network
// æŸ¥çœ‹å¤±è´¥çš„è¯·æ±‚
// æ£€æŸ¥è¯·æ±‚URLã€çŠ¶æ€ç ã€å“åº”å†…å®¹
```

**å¯èƒ½åŸå› **ï¼š
1. åç«¯æœåŠ¡æœªå¯åŠ¨
2. CORSé…ç½®é”™è¯¯
3. APIåœ°å€é…ç½®é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ1ï¼šæ£€æŸ¥åç«¯æœåŠ¡**
```bash
curl http://localhost:8000/api/v1/health
# åº”è¿”å› {"status": "ok"}
```

**æ–¹æ¡ˆ2ï¼šé…ç½®CORS**
```python
# backend/app/main.py
from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

**æ–¹æ¡ˆ3ï¼šæ£€æŸ¥å‰ç«¯APIé…ç½®**
```javascript
// frontend/src/config.js
export const API_BASE_URL = 'http://localhost:8000/api/v1';
```

---

## 6. æ€§èƒ½é—®é¢˜

### æ•…éšœ6.1ï¼šæ–¹æ¡ˆç”Ÿæˆé€Ÿåº¦æ…¢

**ç—‡çŠ¶**ï¼šAIç”Ÿæˆæ–¹æ¡ˆè€—æ—¶è¶…è¿‡10åˆ†é’Ÿ

**æ’æŸ¥**ï¼š
```bash
# æ£€æŸ¥CPUä½¿ç”¨ç‡
top

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
free -m

# æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ
ping open.bigmodel.cn
```

**å¯èƒ½åŸå› **ï¼š
1. æ™ºè°±AIç½‘ç»œå»¶è¿Ÿ
2. æœåŠ¡å™¨èµ„æºä¸è¶³
3. æ•°æ®åº“æŸ¥è¯¢æ…¢
4. å‘é‡æœç´¢æ…¢

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ1ï¼šå¹¶è¡Œç”Ÿæˆç« èŠ‚**
```python
import asyncio

async def generate_all_sections(request):
    tasks = [
        generate_executive_summary(request),
        generate_requirement_analysis(request),
        generate_solution(request),
        # ... å…¶ä»–ç« èŠ‚
    ]
    results = await asyncio.gather(*tasks)
    return results
```

**æ–¹æ¡ˆ2ï¼šä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢**
```python
# ä½¿ç”¨ç´¢å¼•
# ä½¿ç”¨ç¼“å­˜
from functools import lru_cache

@lru_cache(maxsize=100)
def get_similar_proposals(query):
    # æŸ¥è¯¢ç»“æœç¼“å­˜
    pass
```

**æ–¹æ¡ˆ3ï¼šå¢åŠ æœåŠ¡å™¨èµ„æº**
```yaml
# docker-compose.yml
services:
  backend:
    mem_limit: 4g
    cpus: 2.0
```

---

### æ•…éšœ6.2ï¼šæ•°æ®åº“æŸ¥è¯¢æ…¢

**ç—‡çŠ¶**ï¼šAPIå“åº”æ—¶é—´è¶…è¿‡2ç§’

**æ’æŸ¥**ï¼š
```sql
-- MySQLæŸ¥çœ‹æ…¢æŸ¥è¯¢
SHOW VARIABLES LIKE 'slow_query_log';
SHOW VARIABLES LIKE 'long_query_time';

-- æŸ¥çœ‹æ…¢æŸ¥è¯¢æ—¥å¿—
cat /var/log/mysql/slow-query.log

-- åˆ†ææŸ¥è¯¢
EXPLAIN SELECT * FROM proposals WHERE user_id = 1;
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ1ï¼šæ·»åŠ ç´¢å¼•**
```sql
CREATE INDEX idx_proposals_user_id ON proposals(user_id);
CREATE INDEX idx_proposals_status ON proposals(status);
CREATE INDEX idx_proposals_created_at ON proposals(created_at DESC);
```

**æ–¹æ¡ˆ2ï¼šä¼˜åŒ–æŸ¥è¯¢**
```python
# ä½¿ç”¨select_relatedé¢„åŠ è½½å…³è”æ•°æ®
proposals = db.query(Proposal)\
    .options(selectinload(Proposal.user))\
    .filter(Proposal.user_id == user_id)\
    .all()

# åˆ†é¡µæŸ¥è¯¢
proposals = db.query(Proposal)\
    .limit(20)\
    .offset(0)\
    .all()
```

**æ–¹æ¡ˆ3ï¼šä½¿ç”¨ç¼“å­˜**
```python
import redis

redis_client = redis.Redis(host='localhost', port=6379, db=0)

# ç¼“å­˜æŸ¥è¯¢ç»“æœ
cached_result = redis_client.get(f"proposal:{proposal_id}")
if cached_result:
    return json.loads(cached_result)
```

---

## 7. ç½‘ç»œé—®é¢˜

### æ•…éšœ7.1ï¼šæ— æ³•è¿æ¥å¤–éƒ¨æœåŠ¡

**ç—‡çŠ¶**ï¼šæ— æ³•è®¿é—®æ™ºè°±AIã€æ— æ³•ä¸‹è½½ä¾èµ–

**æ’æŸ¥**ï¼š
```bash
# æµ‹è¯•ç½‘ç»œè¿æ¥
ping 8.8.8.8
ping open.bigmodel.cn

# æµ‹è¯•DNSè§£æ
nslookup open.bigmodel.cn

# æ£€æŸ¥é˜²ç«å¢™
sudo iptables -L
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ1ï¼šé…ç½®ä»£ç†**
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export HTTP_PROXY=http://proxy.company.com:8080
export HTTPS_PROXY=http://proxy.company.com:8080

# æˆ–åœ¨.envä¸­é…ç½®
HTTP_PROXY=http://proxy.company.com:8080
HTTPS_PROXY=http://proxy.company.com:8080
```

**æ–¹æ¡ˆ2ï¼šé…ç½®DNS**
```bash
# ç¼–è¾‘/etc/resolv.conf
nameserver 8.8.8.8
nameserver 114.114.114.114
```

---

## 8. æ—¥å¿—åˆ†æ

### 8.1 æ—¥å¿—æ–‡ä»¶ä½ç½®

```
åç«¯æ—¥å¿—ï¼šbackend/logs/app.log
Nginxæ—¥å¿—ï¼š/var/log/nginx/access.log, error.log
Dockeræ—¥å¿—ï¼šdocker-compose logs <service_name>
ç³»ç»Ÿæ—¥å¿—ï¼š/var/log/syslog æˆ– /var/log/messages
```

### 8.2 å¸¸ç”¨æ—¥å¿—å‘½ä»¤

```bash
# å®æ—¶æŸ¥çœ‹æ—¥å¿—
tail -f backend/logs/app.log

# æŸ¥çœ‹æœ€è¿‘100è¡Œ
tail -n 100 backend/logs/app.log

# æœç´¢é”™è¯¯
grep "ERROR" backend/logs/app.log

# æŸ¥çœ‹Dockeræ—¥å¿—
docker-compose logs -f backend
docker-compose logs --tail=100 backend

# æŸ¥çœ‹ç‰¹å®šæ—¶é—´æ®µæ—¥å¿—
grep "2025-11-08 10:" backend/logs/app.log
```

### 8.3 æ—¥å¿—çº§åˆ«

| çº§åˆ« | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| DEBUG | è°ƒè¯•ä¿¡æ¯ | æŸ¥è¯¢å‚æ•°ã€å˜é‡å€¼ |
| INFO | å…³é”®æ“ä½œ | ç”¨æˆ·ç™»å½•ã€æ–‡æ¡£ä¸Šä¼  |
| WARNING | è­¦å‘Šä¿¡æ¯ | æ€§èƒ½è¶…æ—¶ã€èµ„æºä¸è¶³ |
| ERROR | é”™è¯¯ä¿¡æ¯ | APIè°ƒç”¨å¤±è´¥ã€æ•°æ®åº“é”™è¯¯ |
| CRITICAL | ä¸¥é‡é”™è¯¯ | æœåŠ¡å´©æºƒã€æ•°æ®ä¸¢å¤± |

### 8.4 æ—¥å¿—åˆ†æç¤ºä¾‹

**åˆ†ææ–¹æ¡ˆç”Ÿæˆå¤±è´¥**ï¼š
```bash
# æœç´¢ç‰¹å®šæ–¹æ¡ˆIDçš„æ—¥å¿—
grep "proposal_id=123" backend/logs/app.log

# æŸ¥çœ‹è¾“å‡º
2025-11-08 10:15:30 - INFO - å¼€å§‹ç”Ÿæˆæ–¹æ¡ˆ proposal_id=123
2025-11-08 10:15:35 - INFO - æœç´¢ç›¸ä¼¼æ–¹æ¡ˆ...
2025-11-08 10:15:40 - ERROR - æ™ºè°±AIè°ƒç”¨å¤±è´¥: API key is invalid
2025-11-08 10:15:40 - ERROR - æ–¹æ¡ˆç”Ÿæˆå¤±è´¥ proposal_id=123
```

**åˆ†ææ€§èƒ½é—®é¢˜**ï¼š
```bash
# æœç´¢è€—æ—¶è¶…è¿‡5ç§’çš„æ“ä½œ
grep "duration=[5-9]\." backend/logs/app.log
grep "duration=[0-9][0-9]\." backend/logs/app.log

# è¾“å‡ºç¤ºä¾‹
2025-11-08 10:20:15 - WARNING - æ–¹æ¡ˆç”Ÿæˆè€—æ—¶ duration=8.5s proposal_id=456
```

---

## 9. ç´§æ€¥è”ç³»æœºåˆ¶

### 9.1 æ•…éšœåˆ†çº§

| çº§åˆ« | å½±å“èŒƒå›´ | å“åº”æ—¶é—´ | è”ç³»æ–¹å¼ |
|------|---------|---------|---------|
| **P0** | ç³»ç»Ÿå®Œå…¨ä¸å¯ç”¨ | 15åˆ†é’Ÿ | ç”µè¯+çŸ­ä¿¡ |
| **P1** | æ ¸å¿ƒåŠŸèƒ½ä¸å¯ç”¨ | 1å°æ—¶ | ä¼ä¸šå¾®ä¿¡+ç”µè¯ |
| **P2** | éƒ¨åˆ†åŠŸèƒ½å¼‚å¸¸ | 4å°æ—¶ | ä¼ä¸šå¾®ä¿¡+é‚®ä»¶ |
| **P3** | å°é—®é¢˜ | 1å·¥ä½œæ—¥ | é‚®ä»¶+å·¥å• |

### 9.2 è”ç³»æ–¹å¼

**è¿ç»´å›¢é˜Ÿ**ï¼š
- ç”µè¯ï¼š138-XXXX-XXXXï¼ˆ7Ã—24å°æ—¶ï¼‰
- ä¼ä¸šå¾®ä¿¡ï¼š"è¿ç»´æ”¯æŒç¾¤"
- é‚®ç®±ï¼šops@company.com

**å¼€å‘å›¢é˜Ÿ**ï¼š
- ç”µè¯ï¼š139-XXXX-XXXXï¼ˆå·¥ä½œæ—¥ï¼‰
- ä¼ä¸šå¾®ä¿¡ï¼š"æŠ€æœ¯æ”¯æŒç¾¤"
- é‚®ç®±ï¼šdev@company.com

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.2.0  
**æœ€åæ›´æ–°**ï¼š2025-11-08  
**ç»´æŠ¤å›¢é˜Ÿ**ï¼šè¿ç»´å›¢é˜Ÿ  

---

*å®šæœŸæ›´æ–°æ•…éšœæ¡ˆä¾‹ï¼ŒæŒç»­å®Œå–„æ’æŸ¥æ‰‹å†Œï¼*
